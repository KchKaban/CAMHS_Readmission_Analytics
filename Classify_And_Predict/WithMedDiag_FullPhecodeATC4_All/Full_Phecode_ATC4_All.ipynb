{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9947eea4-1f70-40a5-bdbd-eec947e8abdf",
   "metadata": {},
   "source": [
    "#### Task: Classification and Predicition of readmission with medication and diagnosis columns, based on Phenocode and ATC codes of 4 digit length\n",
    "##### Subtasks:\n",
    "1. Classify and Predict for 180 days\n",
    "2. Classify and Predict for 1 year\n",
    "3. Classify and Predict for 2 year\n",
    "4. Classify and Predict for 3 year\n",
    "\n",
    "Description of work done:\n",
    "\n",
    "1. In this scripts the first class `SplitMedicationDiagnosisInUniquePieces` splits all the diagnosia and medication column into unique pieces.\n",
    "2. Then it saves the new data frame with unique diagnosis and medication as new `CSV` file named as `Split_Full_ICD10_ATC`\n",
    "3. Then the second class `ClassifyReadmissionWithMedicationDiagnosis` takes the new `Split_Full_ICD10_ATC` dataset and perform classiciation and prediction\n",
    "4. To run the script replace if you are not using `dotenv` replace`os.getenv(\"FILE_Full_Phecode_ATC_PATH\")` with the path of your file.\n",
    "\n",
    "- Other Important Info: \n",
    "    1. Dataset has NaN values. NaN has been replaced with 0\n",
    "    2. Diagnosis and medication column names\n",
    "- Dataset Used: `/mnt/work/workbench/dipendrp/new-data/Full_Phecode_ATC4.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa2815e-2c18-41cf-93ef-e7dbadc360e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### 1. Classify and Predict for 180 days\n",
    "\n",
    "**`TNE_BO_180` values (0 and 1 are used to classify readmission, where 1 means readmission). Further for prediction only the readmitted patient data is taken and a linear regression model is trained on it to predict the number of days for readmission.**\n",
    "- Dataset Used: `/mnt/work/workbench/dipendrp/new-data/Full_Phecode_ATC4.csv`\n",
    "- Independent variable: `'age', 'remaining_time_countdown','var_no_dates_permonth', 'gender','closingcode', 'aftercode', 'Length_of_Episode', \n",
    "                        'Count_visit','Therapy_ratio', 'Examination_ratio', 'Advisory_ratio','TreatmentPlanning_ratio', 'Outpatient_ratio',\n",
    "                        'Inpatient_daynight_ratio', 'Care_intensity', 'num_diagnoses', 'num_medications', \n",
    "                        and unique 'actual_diag_Phe', 'actual_med_ATC4' `\n",
    "- Dependent Variable: For classification its `TNE_BO_180` and for prediction its `TNE_NO_180` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d678b9-83cc-485e-8572-6ed9ed9d9558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import display\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score,confusion_matrix,precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "######### Split Medication and Diagnosis In Unique Pieces ############\n",
    "#                                                                    #\n",
    "#                                                                    #\n",
    "#                                                                    #\n",
    "######################################################################\n",
    "\n",
    "class SplitMedicationDiagnosisInUniquePieces:\n",
    "    def __init__(self, file1):\n",
    "        self.file1 = file1\n",
    "        self.merged_df = None\n",
    "        self.selected_column_merged_df = None\n",
    "        self.without_diag_medic_selected_column_merged_df = None\n",
    "    \n",
    "    def load_data_to_split(self):\n",
    "        Full_Phecode_ATC4 = pd.read_csv(self.file1)\n",
    "        self.merged_df = Full_Phecode_ATC4\n",
    "        # Specify the names of columns you are interested in here diagnosis and medication column name in the CSV files\n",
    "        self.merged_df = self.merged_df[['episode_id', 'num_diagnoses', 'num_medications', 'pasient', 'age',\n",
    "                                       'remaining_time_countdown', 'var_no_dates_permonth', 'gender',\n",
    "                                       'episode_order', 'islast', 'closingcode', 'aftercode',\n",
    "                                       'episode_start_date', 'episode_end_date', 'tillnextepisode',\n",
    "                                       'Length_of_Episode', 'Cat_LOE', 'TNE_BO_180', 'TNE_NO_180',\n",
    "                                       'TNE_BO_365', 'TNE_NO_365', 'TNE_BO_730', 'TNE_NO_730', 'TNE_BO_1095',\n",
    "                                       'TNE_NO_1095', 'Cat_LOE_desc', 'Count_visit', 'Cat_CV', 'Therapy_ratio',\n",
    "                                       'Examination_ratio', 'Advisory_ratio', 'TreatmentPlanning_ratio',\n",
    "                                       'Outpatient_ratio', 'Inpatient_ratio', 'Inpatient_day_ratio',\n",
    "                                       'Inpatient_daynight_ratio', 'Care_intensity', 'age_group',\n",
    "                                       'closingcode_0', 'closingcode_1', 'closingcode_2', 'closingcode_3',\n",
    "                                       'closingcode_4', 'closingcode_5', 'closingcode_6', 'closingcode_9',\n",
    "                                       'aftercode_1', 'aftercode_2', 'aftercode_3', 'aftercode_4',\n",
    "                                       'aftercode_5', 'gender_0', 'F', 'M', 'MiddleChildhood', 'Preschooler',\n",
    "                                       'Teenager', 'actual_diag_Phe', 'actual_med_ATC4']]\n",
    "        \n",
    "        self.merged_df = self.merged_df.copy(deep=True)\n",
    "        return self.merged_df\n",
    "\n",
    "        \n",
    "    def split_diagnosis_medication_in_unique_pieces(self):\n",
    "        newmerged_df = SplitMedicationDiagnosisInUniquePieces_Obj.load_data_to_split()\n",
    "        # Specify the exact names of diagnosis and medication column to perform the split\n",
    "        columns = ['actual_diag_Phe', 'actual_med_ATC4']\n",
    "        for col in columns:\n",
    "            newmerged_df[col] = newmerged_df[col].apply(lambda d:[] if pd.isnull(d) else d)\n",
    "            newmerged_df[col] = newmerged_df[col].str.replace(\"[\", \"\")\n",
    "            newmerged_df[col] = newmerged_df[col].str.replace(\"]\", \"\")\n",
    "            newmerged_df[col] = newmerged_df[col].str.replace(\"'\", \"\")\n",
    "            newmerged_df[col] = newmerged_df[col].str.replace(\" \", \"\")\n",
    "            newmerged_df[col] = newmerged_df[col].str.split(',')\n",
    "            newmerged_df = newmerged_df.explode(col)\n",
    "            \n",
    "            # Show only top 100 columns names\n",
    "            temp_store_100 = newmerged_df[col].value_counts()\n",
    "            names_only = temp_store_100.index.tolist()\n",
    "            \n",
    "            original_columns = newmerged_df.columns.tolist()\n",
    "            dummies = newmerged_df[col].str.get_dummies(sep=',')\n",
    "            newmerged_df = pd.concat([newmerged_df, dummies], axis=1)\n",
    "            newmerged_df = newmerged_df.drop(col, axis=1)\n",
    "            \n",
    "        newmerged_df.to_csv('Split_Full_Phecode_ATC4.csv',index=False)\n",
    "        \n",
    "    \n",
    "class ClassifyReadmissionWithMedicationDiagnosis:\n",
    "    def __init__(self, file2):\n",
    "        self.file2 = file2\n",
    "        self.merged_df = None\n",
    "        self.selected_column_merged_df = None\n",
    "        self.without_diag_medic_selected_column_merged_df = None\n",
    "    \n",
    "    def load_data(self):\n",
    "        original_df_1 = pd.read_csv(self.file2)\n",
    "        self.merged_df = original_df_1[['num_diagnoses', 'num_medications', 'remaining_time_countdown', 'var_no_dates_permonth','Length_of_Episode', 'Count_visit', 'Therapy_ratio','Examination_ratio', 'Advisory_ratio',\n",
    "        'TreatmentPlanning_ratio','Outpatient_ratio','Inpatient_daynight_ratio', 'Care_intensity', 'closingcode_0', 'closingcode_1', 'closingcode_2', 'closingcode_3','closingcode_4', 'closingcode_5', 'closingcode_6', 'closingcode_9',\n",
    "        'aftercode_1', 'aftercode_2', 'aftercode_3', 'aftercode_4','aftercode_5', 'gender_0', 'F', 'M', 'MiddleChildhood', 'Preschooler','Teenager', 'TNE_NO_180','TNE_BO_180',\n",
    "        '010', '0703', '0704', '079', '0792', '1000', '1008',\n",
    "       '1009', '1011', '1013', '1015', '136', '1499', '1551', '1701', '1702',\n",
    "       '18911', '1911', '19111', '1994', '201', '2022', '20411', '20421',\n",
    "       '2441', '2442', '2444', '2445', '24521', '2501', '25011', '2502',\n",
    "       '2531', '25311', '2532', '2553', '2564', '259', '260', '2602', '2612',\n",
    "       '2614', '262', '2701', '2713', '27614', '2781', '2791', '2801', '28731',\n",
    "       '288', '28811', '2903', '2911', '2914', '2922', '295', '2951', '2952',\n",
    "       '2953', '296', '2961', '29622', '2972', '300', '3001', '3003', '3004',\n",
    "       '3008', '3009', '301', '3011', '3012', '302', '303', '3031', '3033',\n",
    "       '3034', '304', '3052', '306', '3069', '312', '3123', '313', '3131',\n",
    "       '3132', '3133', '315', '3151', '3152', '3153', '316', '317', '323',\n",
    "       '324', '327', '3274', '32741', '3275', '3276', '3311', '339', '340',\n",
    "       '3401', '341', '343', '344', '345', '3451', '34511', '34512', '3453',\n",
    "       '347', '3484', '357', '3591', '3592', '3621', '365', '3671', '3672',\n",
    "       '3678', '3679', '368', '3681', '3684', '3695', '3711', '3781', '3782',\n",
    "       '3811', '389', '3891', '3892', '3894', '3895', '42711', '4332', '4338',\n",
    "       '4589', '472', '4741', '4742', '476', '4801', '495', '496', '499',\n",
    "       '506', '5091', '510', '53011', '53014', '5302', '5305', '535', '5551',\n",
    "       '5552', '55521', '558', '5611', '563', '564', '5641', '565', '57181',\n",
    "       '5772', '591', '5921', '5965', '5994', '6041', '62611', '6264', '637',\n",
    "       '6491', '656', '6562', '6563', '6564', '657', '658', '661', '691',\n",
    "       '6941', '69542', '6964', '7061', '71011', '7142', '7169', '7282',\n",
    "       '7321', '733', '736', '7373', '739', '745', '7471', '74711', '74712',\n",
    "       '74713', '7472', '748', '749', '7491', '7492', '75011', '75013',\n",
    "       '75021', '75112', '7512', '75121', '75211', '7522', '7531', '7551',\n",
    "       '7554', '7556', '75561', '756', '7561', '758', '7581', '759', '760',\n",
    "       '770', '773', '7981', '8003', '802', '8032', '8033', '805', '817',\n",
    "       '818', '819', '830', '835', '871', '907', '915', '930', '939', '946',\n",
    "       '947', '949', '969', '979', '981', 'A02B', 'A03F', 'A06A', 'A06B',\n",
    "       'A07A', 'A10B', 'A11E', 'A12A', 'A12B', 'B03A', 'B03B', 'C02A', 'C07A',\n",
    "       'C09A', 'D01A', 'D06A', 'D06B', 'D07A', 'D07B', 'D07X', 'D09A', 'D10A',\n",
    "       'G03A', 'G03C', 'G03F', 'G03H', 'H01B', 'H02A', 'J01C', 'J01F', 'J05A',\n",
    "       'M01A', 'N01B', 'N02A', 'N02B', 'N02C', 'N03A', 'N05A', 'N05B', 'N05C',\n",
    "       'N06A', 'N06B', 'N07B', 'NO6B', 'R01A', 'R03A', 'R03B', 'R05D', 'R06A',\n",
    "       'S01A', 'S01G']]\n",
    "        \n",
    "        \n",
    "       \n",
    "        # fill nan values in independent column\n",
    "        self.merged_df['num_diagnoses'].fillna(0, inplace=True)\n",
    "        self.merged_df['num_medications'].fillna(0, inplace=True)\n",
    "        self.merged_df['Outpatient_ratio'].fillna(0, inplace=True)\n",
    "        self.merged_df['Inpatient_daynight_ratio'].fillna(0, inplace=True)  \n",
    "        self.merged_df['Therapy_ratio'].fillna(0, inplace=True)\n",
    "        self.merged_df['Examination_ratio'].fillna(0, inplace=True)\n",
    "        self.merged_df['Advisory_ratio'].fillna(0, inplace=True)\n",
    "        self.merged_df['TreatmentPlanning_ratio'].fillna(0, inplace=True)\n",
    "        \n",
    "        \n",
    "        # define dependent variables\n",
    "        self.dependent_variable_TNE_BO_180 = self.merged_df[['TNE_BO_180']]\n",
    "        \n",
    "        self.independent_variable = self.merged_df[['num_diagnoses', 'num_medications', 'remaining_time_countdown', 'var_no_dates_permonth','Length_of_Episode', 'Count_visit', 'Therapy_ratio','Examination_ratio', 'Advisory_ratio',\n",
    "        'TreatmentPlanning_ratio','Outpatient_ratio','Inpatient_daynight_ratio', 'Care_intensity', 'closingcode_0', 'closingcode_1', 'closingcode_2', 'closingcode_3','closingcode_4', 'closingcode_5', 'closingcode_6', 'closingcode_9',\n",
    "        'aftercode_1', 'aftercode_2', 'aftercode_3', 'aftercode_4','aftercode_5', 'gender_0', 'F', 'M', 'MiddleChildhood', 'Preschooler','Teenager',\n",
    "        '010', '0703', '0704', '079', '0792', '1000', '1008',\n",
    "       '1009', '1011', '1013', '1015', '136', '1499', '1551', '1701', '1702',\n",
    "       '18911', '1911', '19111', '1994', '201', '2022', '20411', '20421',\n",
    "       '2441', '2442', '2444', '2445', '24521', '2501', '25011', '2502',\n",
    "       '2531', '25311', '2532', '2553', '2564', '259', '260', '2602', '2612',\n",
    "       '2614', '262', '2701', '2713', '27614', '2781', '2791', '2801', '28731',\n",
    "       '288', '28811', '2903', '2911', '2914', '2922', '295', '2951', '2952',\n",
    "       '2953', '296', '2961', '29622', '2972', '300', '3001', '3003', '3004',\n",
    "       '3008', '3009', '301', '3011', '3012', '302', '303', '3031', '3033',\n",
    "       '3034', '304', '3052', '306', '3069', '312', '3123', '313', '3131',\n",
    "       '3132', '3133', '315', '3151', '3152', '3153', '316', '317', '323',\n",
    "       '324', '327', '3274', '32741', '3275', '3276', '3311', '339', '340',\n",
    "       '3401', '341', '343', '344', '345', '3451', '34511', '34512', '3453',\n",
    "       '347', '3484', '357', '3591', '3592', '3621', '365', '3671', '3672',\n",
    "       '3678', '3679', '368', '3681', '3684', '3695', '3711', '3781', '3782',\n",
    "       '3811', '389', '3891', '3892', '3894', '3895', '42711', '4332', '4338',\n",
    "       '4589', '472', '4741', '4742', '476', '4801', '495', '496', '499',\n",
    "       '506', '5091', '510', '53011', '53014', '5302', '5305', '535', '5551',\n",
    "       '5552', '55521', '558', '5611', '563', '564', '5641', '565', '57181',\n",
    "       '5772', '591', '5921', '5965', '5994', '6041', '62611', '6264', '637',\n",
    "       '6491', '656', '6562', '6563', '6564', '657', '658', '661', '691',\n",
    "       '6941', '69542', '6964', '7061', '71011', '7142', '7169', '7282',\n",
    "       '7321', '733', '736', '7373', '739', '745', '7471', '74711', '74712',\n",
    "       '74713', '7472', '748', '749', '7491', '7492', '75011', '75013',\n",
    "       '75021', '75112', '7512', '75121', '75211', '7522', '7531', '7551',\n",
    "       '7554', '7556', '75561', '756', '7561', '758', '7581', '759', '760',\n",
    "       '770', '773', '7981', '8003', '802', '8032', '8033', '805', '817',\n",
    "       '818', '819', '830', '835', '871', '907', '915', '930', '939', '946',\n",
    "       '947', '949', '969', '979', '981', 'A02B', 'A03F', 'A06A', 'A06B',\n",
    "       'A07A', 'A10B', 'A11E', 'A12A', 'A12B', 'B03A', 'B03B', 'C02A', 'C07A',\n",
    "       'C09A', 'D01A', 'D06A', 'D06B', 'D07A', 'D07B', 'D07X', 'D09A', 'D10A',\n",
    "       'G03A', 'G03C', 'G03F', 'G03H', 'H01B', 'H02A', 'J01C', 'J01F', 'J05A',\n",
    "       'M01A', 'N01B', 'N02A', 'N02B', 'N02C', 'N03A', 'N05A', 'N05B', 'N05C',\n",
    "       'N06A', 'N06B', 'N07B', 'NO6B', 'R01A', 'R03A', 'R03B', 'R05D', 'R06A',\n",
    "       'S01A', 'S01G']]\n",
    "        \n",
    "        return self.merged_df, self.dependent_variable_TNE_BO_180, self.independent_variable \n",
    "    \n",
    "    # To train and view the reasult of binary and multiclass classifier        \n",
    "    def train_classifier_with_medication_diagnosis(self):\n",
    "        dependent_variables = [self.dependent_variable_TNE_BO_180]\n",
    "        \n",
    "        # to define the weight of output class, to resolve imbalanced output/dataset\n",
    "        dependent_variable_names = {'self.dependent_variable_TNE_BO_180': 'TNE_BO_180'}\n",
    "        class_weights = {'TNE_BO_180': {0:10, 1:270}}\n",
    "              \n",
    "        #for dependent_variable in dependent_variables:\n",
    "        for variable_name, dependent_variable in zip(dependent_variable_names.values(), dependent_variables):\n",
    "            logistic_prediction_model = LogisticRegression(class_weight=class_weights[variable_name])\n",
    "            X_train, X_test, y_train, y_test = train_test_split(self.independent_variable, dependent_variable, train_size=0.7)\n",
    "            logistic_prediction_model.fit(X_train,y_train)\n",
    "            y_pred = logistic_prediction_model.predict(X_test)\n",
    "            \n",
    "            # Checks if the output category for classification is binary or multiclass\n",
    "            category_count = int(y_train.nunique())\n",
    "            print(f'\\n****** Evaluation result {variable_name} as dependent variable ******')\n",
    "            # For binary class classification \n",
    "            if category_count == 2:\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, average='binary')\n",
    "                recall = recall_score(y_test, y_pred, average='binary')\n",
    "                f1 = f1_score(y_test, y_pred, average='binary')\n",
    "                \n",
    "                print(f\"Accuracy: {accuracy}\")\n",
    "                print(f\"Precision: {precision}\")\n",
    "                print(f\"Recall: {recall}\")\n",
    "                print(f\"F1score: {f1}\")\n",
    "                print(\"Confused matrix:\")\n",
    "                conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                tn, fp, fn, tp = conf_matrix.ravel()\n",
    "                print(conf_matrix)\n",
    "                print(f\"True Negative (TN): {tn}\")\n",
    "                print(f\"False Positive (FP): {fp}\")\n",
    "                print(f\"False Negative (FN): {fn}\")\n",
    "                print(f\"True Positive (TP): {tp}\")\n",
    "                print(classification_report(y_test, y_pred))\n",
    "            \n",
    "            # For binary class classification \n",
    "            else:\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, average='weighted')\n",
    "                recall = recall_score(y_test, y_pred, average='weighted')\n",
    "                f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "                \n",
    "                print(f\"Accuracy: {accuracy}\")\n",
    "                print(f\"Precision: {precision}\")\n",
    "                print(f\"Recall: {recall}\")\n",
    "                print(f\"F1score: {f1}\")\n",
    "                conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                print(\"Confused matrix:\")\n",
    "                print(conf_matrix)\n",
    "                print(classification_report(y_test, y_pred))\n",
    "                \n",
    "    def prediction_with_medication_diagnosis(self):\n",
    "        # Select all corresponding columns with values in TNE_NO_180\n",
    "        self.merged_df = self.merged_df.dropna(subset=['TNE_NO_180'])\n",
    "        \n",
    "        # define dependent variables\n",
    "        self.dependent_variable_TNE_NO_180 = self.merged_df[['TNE_NO_180']]\n",
    "        # define independent variables \n",
    "        self.independent_variable = self.merged_df[['num_diagnoses', 'num_medications', 'remaining_time_countdown', 'var_no_dates_permonth','Length_of_Episode', 'Count_visit', 'Therapy_ratio','Examination_ratio', 'Advisory_ratio',\n",
    "        'TreatmentPlanning_ratio','Outpatient_ratio','Inpatient_daynight_ratio', 'Care_intensity', 'closingcode_0', 'closingcode_1', 'closingcode_2', 'closingcode_3','closingcode_4', 'closingcode_5', 'closingcode_6', 'closingcode_9',\n",
    "        'aftercode_1', 'aftercode_2', 'aftercode_3', 'aftercode_4','aftercode_5', 'gender_0', 'F', 'M', 'MiddleChildhood', 'Preschooler','Teenager',\n",
    "        '010', '0703', '0704', '079', '0792', '1000', '1008',\n",
    "       '1009', '1011', '1013', '1015', '136', '1499', '1551', '1701', '1702',\n",
    "       '18911', '1911', '19111', '1994', '201', '2022', '20411', '20421',\n",
    "       '2441', '2442', '2444', '2445', '24521', '2501', '25011', '2502',\n",
    "       '2531', '25311', '2532', '2553', '2564', '259', '260', '2602', '2612',\n",
    "       '2614', '262', '2701', '2713', '27614', '2781', '2791', '2801', '28731',\n",
    "       '288', '28811', '2903', '2911', '2914', '2922', '295', '2951', '2952',\n",
    "       '2953', '296', '2961', '29622', '2972', '300', '3001', '3003', '3004',\n",
    "       '3008', '3009', '301', '3011', '3012', '302', '303', '3031', '3033',\n",
    "       '3034', '304', '3052', '306', '3069', '312', '3123', '313', '3131',\n",
    "       '3132', '3133', '315', '3151', '3152', '3153', '316', '317', '323',\n",
    "       '324', '327', '3274', '32741', '3275', '3276', '3311', '339', '340',\n",
    "       '3401', '341', '343', '344', '345', '3451', '34511', '34512', '3453',\n",
    "       '347', '3484', '357', '3591', '3592', '3621', '365', '3671', '3672',\n",
    "       '3678', '3679', '368', '3681', '3684', '3695', '3711', '3781', '3782',\n",
    "       '3811', '389', '3891', '3892', '3894', '3895', '42711', '4332', '4338',\n",
    "       '4589', '472', '4741', '4742', '476', '4801', '495', '496', '499',\n",
    "       '506', '5091', '510', '53011', '53014', '5302', '5305', '535', '5551',\n",
    "       '5552', '55521', '558', '5611', '563', '564', '5641', '565', '57181',\n",
    "       '5772', '591', '5921', '5965', '5994', '6041', '62611', '6264', '637',\n",
    "       '6491', '656', '6562', '6563', '6564', '657', '658', '661', '691',\n",
    "       '6941', '69542', '6964', '7061', '71011', '7142', '7169', '7282',\n",
    "       '7321', '733', '736', '7373', '739', '745', '7471', '74711', '74712',\n",
    "       '74713', '7472', '748', '749', '7491', '7492', '75011', '75013',\n",
    "       '75021', '75112', '7512', '75121', '75211', '7522', '7531', '7551',\n",
    "       '7554', '7556', '75561', '756', '7561', '758', '7581', '759', '760',\n",
    "       '770', '773', '7981', '8003', '802', '8032', '8033', '805', '817',\n",
    "       '818', '819', '830', '835', '871', '907', '915', '930', '939', '946',\n",
    "       '947', '949', '969', '979', '981', 'A02B', 'A03F', 'A06A', 'A06B',\n",
    "       'A07A', 'A10B', 'A11E', 'A12A', 'A12B', 'B03A', 'B03B', 'C02A', 'C07A',\n",
    "       'C09A', 'D01A', 'D06A', 'D06B', 'D07A', 'D07B', 'D07X', 'D09A', 'D10A',\n",
    "       'G03A', 'G03C', 'G03F', 'G03H', 'H01B', 'H02A', 'J01C', 'J01F', 'J05A',\n",
    "       'M01A', 'N01B', 'N02A', 'N02B', 'N02C', 'N03A', 'N05A', 'N05B', 'N05C',\n",
    "       'N06A', 'N06B', 'N07B', 'NO6B', 'R01A', 'R03A', 'R03B', 'R05D', 'R06A',\n",
    "       'S01A', 'S01G']]\n",
    "        \n",
    "        dependent_variables = [self.dependent_variable_TNE_NO_180]\n",
    "        dependent_variable_names = {'self.dependent_variable_TNE_NO_180':'TNE_NO_180'}\n",
    "        #for dependent_variable in dependent_variables:\n",
    "        for variable_name, dependent_variable in zip(dependent_variable_names.values(), dependent_variables):\n",
    "            linear_prediction_model = LinearRegression()\n",
    "            X_train, X_temp, y_train, y_temp = train_test_split(self.independent_variable, dependent_variable, train_size=0.7)\n",
    "            X_test,X_eval,y_test,y_eval = train_test_split(X_temp,y_temp,test_size=0.33)\n",
    "            linear_prediction_model.fit(X_train,y_train)\n",
    "            y_pred = linear_prediction_model.predict(X_test)\n",
    "            print(f'\\n****** Prediction Model Evaluation result  {variable_name} as dependent variable ******')\n",
    "            y_pred = linear_prediction_model.predict(X_test)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            print('R-squared:', r2)\n",
    "            print('Mean squared error:', mse)\n",
    "                \n",
    "\n",
    "SplitMedicationDiagnosisInUniquePieces_Obj = SplitMedicationDiagnosisInUniquePieces(os.getenv(\"FILE_Full_Phecode_ATC_PATH\"))\n",
    "SplitMedicationDiagnosisInUniquePieces_Obj.split_diagnosis_medication_in_unique_pieces()\n",
    "\n",
    "ClassifyReadmissionWithMedicationDiagnosis_Obj = ClassifyReadmissionWithMedicationDiagnosis('Split_Full_Phecode_ATC4.csv')\n",
    "merged_df, dependent_variable_TNE_BO_180, independent_variable  = ClassifyReadmissionWithMedicationDiagnosis_Obj.load_data()\n",
    "ClassifyReadmissionWithMedicationDiagnosis_Obj.train_classifier_with_medication_diagnosis()\n",
    "ClassifyReadmissionWithMedicationDiagnosis_Obj.prediction_with_medication_diagnosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1745fe-8f69-40cb-8af4-39e5f25b24b7",
   "metadata": {},
   "source": [
    "##### 2. Classify and Predict for 1 year\n",
    "\n",
    "**`TNE_BO_365` values (0 and 1 are used to classify readmission, where 1 means readmission). Further for prediction only the readmitted patient data is taken and a linear regression model is trained on it to predict the number of days for readmission.**\n",
    "- Dataset Used: `/mnt/work/workbench/dipendrp/new-data/Full_Phecode_ATC4.csv`\n",
    "- Independent variable: `'age', 'remaining_time_countdown','var_no_dates_permonth', 'gender','closingcode', 'aftercode', 'Length_of_Episode', \n",
    "                        'Count_visit','Therapy_ratio', 'Examination_ratio', 'Advisory_ratio','TreatmentPlanning_ratio', 'Outpatient_ratio',\n",
    "                        'Inpatient_daynight_ratio', 'Care_intensity', 'num_diagnoses', 'num_medications', \n",
    "                        and unique 'actual_diag_Phe', 'actual_med_ATC4' `\n",
    "- Dependent Variable: For classification its `TNE_BO_365` and for prediction its `TNE_NO_365`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa975b75-2377-4b27-8845-b54cd9517b44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import display\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score,confusion_matrix,precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "######### Split Medication and Diagnosis In Unique Pieces ############\n",
    "#                                                                    #\n",
    "#                                                                    #\n",
    "#                                                                    #\n",
    "######################################################################\n",
    "\n",
    "class SplitMedicationDiagnosisInUniquePieces:\n",
    "    def __init__(self, file1):\n",
    "        self.file1 = file1\n",
    "        self.merged_df = None\n",
    "        self.selected_column_merged_df = None\n",
    "        self.without_diag_medic_selected_column_merged_df = None\n",
    "    \n",
    "    def load_data_to_split(self):\n",
    "        Full_Phecode_ATC4 = pd.read_csv(self.file1)\n",
    "        self.merged_df = Full_Phecode_ATC4\n",
    "        # Specify the names of columns you are interested in here diagnosis and medication column name in the CSV files\n",
    "        self.merged_df = self.merged_df[['episode_id', 'num_diagnoses', 'num_medications', 'pasient', 'age',\n",
    "                                       'remaining_time_countdown', 'var_no_dates_permonth', 'gender',\n",
    "                                       'episode_order', 'islast', 'closingcode', 'aftercode',\n",
    "                                       'episode_start_date', 'episode_end_date', 'tillnextepisode',\n",
    "                                       'Length_of_Episode', 'Cat_LOE', 'TNE_BO_180', 'TNE_NO_180',\n",
    "                                       'TNE_BO_365', 'TNE_NO_365', 'TNE_BO_730', 'TNE_NO_730', 'TNE_BO_1095',\n",
    "                                       'TNE_NO_1095', 'Cat_LOE_desc', 'Count_visit', 'Cat_CV', 'Therapy_ratio',\n",
    "                                       'Examination_ratio', 'Advisory_ratio', 'TreatmentPlanning_ratio',\n",
    "                                       'Outpatient_ratio', 'Inpatient_ratio', 'Inpatient_day_ratio',\n",
    "                                       'Inpatient_daynight_ratio', 'Care_intensity', 'age_group',\n",
    "                                       'closingcode_0', 'closingcode_1', 'closingcode_2', 'closingcode_3',\n",
    "                                       'closingcode_4', 'closingcode_5', 'closingcode_6', 'closingcode_9',\n",
    "                                       'aftercode_1', 'aftercode_2', 'aftercode_3', 'aftercode_4',\n",
    "                                       'aftercode_5', 'gender_0', 'F', 'M', 'MiddleChildhood', 'Preschooler',\n",
    "                                       'Teenager', 'actual_diag_Phe', 'actual_med_ATC4']]\n",
    "        \n",
    "        self.merged_df = self.merged_df.copy(deep=True)\n",
    "        return self.merged_df\n",
    "\n",
    "        \n",
    "    def split_diagnosis_medication_in_unique_pieces(self):\n",
    "        newmerged_df = SplitMedicationDiagnosisInUniquePieces_Obj.load_data_to_split()\n",
    "        # Specify the exact names of diagnosis and medication column to perform the split\n",
    "        columns = ['actual_diag_Phe', 'actual_med_ATC4']\n",
    "        for col in columns:\n",
    "            newmerged_df[col] = newmerged_df[col].apply(lambda d:[] if pd.isnull(d) else d)\n",
    "            newmerged_df[col] = newmerged_df[col].str.replace(\"[\", \"\")\n",
    "            newmerged_df[col] = newmerged_df[col].str.replace(\"]\", \"\")\n",
    "            newmerged_df[col] = newmerged_df[col].str.replace(\"'\", \"\")\n",
    "            newmerged_df[col] = newmerged_df[col].str.replace(\" \", \"\")\n",
    "            newmerged_df[col] = newmerged_df[col].str.split(',')\n",
    "            newmerged_df = newmerged_df.explode(col)\n",
    "            \n",
    "            # Show only top 100 columns names\n",
    "            temp_store_100 = newmerged_df[col].value_counts()\n",
    "            names_only = temp_store_100.index.tolist()\n",
    "            \n",
    "            original_columns = newmerged_df.columns.tolist()\n",
    "            dummies = newmerged_df[col].str.get_dummies(sep=',')\n",
    "            newmerged_df = pd.concat([newmerged_df, dummies], axis=1)\n",
    "            newmerged_df = newmerged_df.drop(col, axis=1)\n",
    "            \n",
    "        newmerged_df.to_csv('Split_Full_Phecode_ATC4.csv',index=False)\n",
    "        \n",
    "    \n",
    "class ClassifyReadmissionWithMedicationDiagnosis:\n",
    "    def __init__(self, file2):\n",
    "        self.file2 = file2\n",
    "        self.merged_df = None\n",
    "        self.selected_column_merged_df = None\n",
    "        self.without_diag_medic_selected_column_merged_df = None\n",
    "    \n",
    "    def load_data(self):\n",
    "        original_df_1 = pd.read_csv(self.file2)\n",
    "        self.merged_df = original_df_1[['num_diagnoses', 'num_medications', 'remaining_time_countdown', 'var_no_dates_permonth','Length_of_Episode', 'Count_visit', 'Therapy_ratio','Examination_ratio', 'Advisory_ratio',\n",
    "        'TreatmentPlanning_ratio','Outpatient_ratio','Inpatient_daynight_ratio', 'Care_intensity', 'closingcode_0', 'closingcode_1', 'closingcode_2', 'closingcode_3','closingcode_4', 'closingcode_5', 'closingcode_6', 'closingcode_9',\n",
    "        'aftercode_1', 'aftercode_2', 'aftercode_3', 'aftercode_4','aftercode_5', 'gender_0', 'F', 'M', 'MiddleChildhood', 'Preschooler','Teenager', 'TNE_NO_365','TNE_BO_365',\n",
    "        '010', '0703', '0704', '079', '0792', '1000', '1008',\n",
    "       '1009', '1011', '1013', '1015', '136', '1499', '1551', '1701', '1702',\n",
    "       '18911', '1911', '19111', '1994', '201', '2022', '20411', '20421',\n",
    "       '2441', '2442', '2444', '2445', '24521', '2501', '25011', '2502',\n",
    "       '2531', '25311', '2532', '2553', '2564', '259', '260', '2602', '2612',\n",
    "       '2614', '262', '2701', '2713', '27614', '2781', '2791', '2801', '28731',\n",
    "       '288', '28811', '2903', '2911', '2914', '2922', '295', '2951', '2952',\n",
    "       '2953', '296', '2961', '29622', '2972', '300', '3001', '3003', '3004',\n",
    "       '3008', '3009', '301', '3011', '3012', '302', '303', '3031', '3033',\n",
    "       '3034', '304', '3052', '306', '3069', '312', '3123', '313', '3131',\n",
    "       '3132', '3133', '315', '3151', '3152', '3153', '316', '317', '323',\n",
    "       '324', '327', '3274', '32741', '3275', '3276', '3311', '339', '340',\n",
    "       '3401', '341', '343', '344', '345', '3451', '34511', '34512', '3453',\n",
    "       '347', '3484', '357', '3591', '3592', '3621', '365', '3671', '3672',\n",
    "       '3678', '3679', '368', '3681', '3684', '3695', '3711', '3781', '3782',\n",
    "       '3811', '389', '3891', '3892', '3894', '3895', '42711', '4332', '4338',\n",
    "       '4589', '472', '4741', '4742', '476', '4801', '495', '496', '499',\n",
    "       '506', '5091', '510', '53011', '53014', '5302', '5305', '535', '5551',\n",
    "       '5552', '55521', '558', '5611', '563', '564', '5641', '565', '57181',\n",
    "       '5772', '591', '5921', '5965', '5994', '6041', '62611', '6264', '637',\n",
    "       '6491', '656', '6562', '6563', '6564', '657', '658', '661', '691',\n",
    "       '6941', '69542', '6964', '7061', '71011', '7142', '7169', '7282',\n",
    "       '7321', '733', '736', '7373', '739', '745', '7471', '74711', '74712',\n",
    "       '74713', '7472', '748', '749', '7491', '7492', '75011', '75013',\n",
    "       '75021', '75112', '7512', '75121', '75211', '7522', '7531', '7551',\n",
    "       '7554', '7556', '75561', '756', '7561', '758', '7581', '759', '760',\n",
    "       '770', '773', '7981', '8003', '802', '8032', '8033', '805', '817',\n",
    "       '818', '819', '830', '835', '871', '907', '915', '930', '939', '946',\n",
    "       '947', '949', '969', '979', '981', 'A02B', 'A03F', 'A06A', 'A06B',\n",
    "       'A07A', 'A10B', 'A11E', 'A12A', 'A12B', 'B03A', 'B03B', 'C02A', 'C07A',\n",
    "       'C09A', 'D01A', 'D06A', 'D06B', 'D07A', 'D07B', 'D07X', 'D09A', 'D10A',\n",
    "       'G03A', 'G03C', 'G03F', 'G03H', 'H01B', 'H02A', 'J01C', 'J01F', 'J05A',\n",
    "       'M01A', 'N01B', 'N02A', 'N02B', 'N02C', 'N03A', 'N05A', 'N05B', 'N05C',\n",
    "       'N06A', 'N06B', 'N07B', 'NO6B', 'R01A', 'R03A', 'R03B', 'R05D', 'R06A',\n",
    "       'S01A', 'S01G']]\n",
    "        \n",
    "        \n",
    "       \n",
    "        # fill nan values in independent column\n",
    "        self.merged_df['num_diagnoses'].fillna(0, inplace=True)\n",
    "        self.merged_df['num_medications'].fillna(0, inplace=True)\n",
    "        self.merged_df['Outpatient_ratio'].fillna(0, inplace=True)\n",
    "        self.merged_df['Inpatient_daynight_ratio'].fillna(0, inplace=True)  \n",
    "        self.merged_df['Therapy_ratio'].fillna(0, inplace=True)\n",
    "        self.merged_df['Examination_ratio'].fillna(0, inplace=True)\n",
    "        self.merged_df['Advisory_ratio'].fillna(0, inplace=True)\n",
    "        self.merged_df['TreatmentPlanning_ratio'].fillna(0, inplace=True)\n",
    "        \n",
    "        \n",
    "        # define dependent variables\n",
    "        self.dependent_variable_TNE_BO_365 = self.merged_df[['TNE_BO_365']]\n",
    "        \n",
    "        self.independent_variable = self.merged_df[['num_diagnoses', 'num_medications', 'remaining_time_countdown', 'var_no_dates_permonth','Length_of_Episode', 'Count_visit', 'Therapy_ratio','Examination_ratio', 'Advisory_ratio',\n",
    "        'TreatmentPlanning_ratio','Outpatient_ratio','Inpatient_daynight_ratio', 'Care_intensity', 'closingcode_0', 'closingcode_1', 'closingcode_2', 'closingcode_3','closingcode_4', 'closingcode_5', 'closingcode_6', 'closingcode_9',\n",
    "        'aftercode_1', 'aftercode_2', 'aftercode_3', 'aftercode_4','aftercode_5', 'gender_0', 'F', 'M', 'MiddleChildhood', 'Preschooler','Teenager',\n",
    "        '010', '0703', '0704', '079', '0792', '1000', '1008',\n",
    "       '1009', '1011', '1013', '1015', '136', '1499', '1551', '1701', '1702',\n",
    "       '18911', '1911', '19111', '1994', '201', '2022', '20411', '20421',\n",
    "       '2441', '2442', '2444', '2445', '24521', '2501', '25011', '2502',\n",
    "       '2531', '25311', '2532', '2553', '2564', '259', '260', '2602', '2612',\n",
    "       '2614', '262', '2701', '2713', '27614', '2781', '2791', '2801', '28731',\n",
    "       '288', '28811', '2903', '2911', '2914', '2922', '295', '2951', '2952',\n",
    "       '2953', '296', '2961', '29622', '2972', '300', '3001', '3003', '3004',\n",
    "       '3008', '3009', '301', '3011', '3012', '302', '303', '3031', '3033',\n",
    "       '3034', '304', '3052', '306', '3069', '312', '3123', '313', '3131',\n",
    "       '3132', '3133', '315', '3151', '3152', '3153', '316', '317', '323',\n",
    "       '324', '327', '3274', '32741', '3275', '3276', '3311', '339', '340',\n",
    "       '3401', '341', '343', '344', '345', '3451', '34511', '34512', '3453',\n",
    "       '347', '3484', '357', '3591', '3592', '3621', '365', '3671', '3672',\n",
    "       '3678', '3679', '368', '3681', '3684', '3695', '3711', '3781', '3782',\n",
    "       '3811', '389', '3891', '3892', '3894', '3895', '42711', '4332', '4338',\n",
    "       '4589', '472', '4741', '4742', '476', '4801', '495', '496', '499',\n",
    "       '506', '5091', '510', '53011', '53014', '5302', '5305', '535', '5551',\n",
    "       '5552', '55521', '558', '5611', '563', '564', '5641', '565', '57181',\n",
    "       '5772', '591', '5921', '5965', '5994', '6041', '62611', '6264', '637',\n",
    "       '6491', '656', '6562', '6563', '6564', '657', '658', '661', '691',\n",
    "       '6941', '69542', '6964', '7061', '71011', '7142', '7169', '7282',\n",
    "       '7321', '733', '736', '7373', '739', '745', '7471', '74711', '74712',\n",
    "       '74713', '7472', '748', '749', '7491', '7492', '75011', '75013',\n",
    "       '75021', '75112', '7512', '75121', '75211', '7522', '7531', '7551',\n",
    "       '7554', '7556', '75561', '756', '7561', '758', '7581', '759', '760',\n",
    "       '770', '773', '7981', '8003', '802', '8032', '8033', '805', '817',\n",
    "       '818', '819', '830', '835', '871', '907', '915', '930', '939', '946',\n",
    "       '947', '949', '969', '979', '981', 'A02B', 'A03F', 'A06A', 'A06B',\n",
    "       'A07A', 'A10B', 'A11E', 'A12A', 'A12B', 'B03A', 'B03B', 'C02A', 'C07A',\n",
    "       'C09A', 'D01A', 'D06A', 'D06B', 'D07A', 'D07B', 'D07X', 'D09A', 'D10A',\n",
    "       'G03A', 'G03C', 'G03F', 'G03H', 'H01B', 'H02A', 'J01C', 'J01F', 'J05A',\n",
    "       'M01A', 'N01B', 'N02A', 'N02B', 'N02C', 'N03A', 'N05A', 'N05B', 'N05C',\n",
    "       'N06A', 'N06B', 'N07B', 'NO6B', 'R01A', 'R03A', 'R03B', 'R05D', 'R06A',\n",
    "       'S01A', 'S01G']]\n",
    "        \n",
    "        return self.merged_df, self.dependent_variable_TNE_BO_365, self.independent_variable \n",
    "    \n",
    "    # To train and view the reasult of binary and multiclass classifier        \n",
    "    def train_classifier_with_medication_diagnosis(self):\n",
    "        dependent_variables = [self.dependent_variable_TNE_BO_365]\n",
    "        \n",
    "        # to define the weight of output class, to resolve imbalanced output/dataset\n",
    "        dependent_variable_names = {'self.dependent_variable_TNE_BO_365': 'TNE_BO_365'}\n",
    "        class_weights = {'TNE_BO_365': {0:10, 1:270}}\n",
    "              \n",
    "        #for dependent_variable in dependent_variables:\n",
    "        for variable_name, dependent_variable in zip(dependent_variable_names.values(), dependent_variables):\n",
    "            logistic_prediction_model = LogisticRegression(class_weight=class_weights[variable_name])\n",
    "            X_train, X_test, y_train, y_test = train_test_split(self.independent_variable, dependent_variable, train_size=0.7)\n",
    "            logistic_prediction_model.fit(X_train,y_train)\n",
    "            y_pred = logistic_prediction_model.predict(X_test)\n",
    "            \n",
    "            # Checks if the output category for classification is binary or multiclass\n",
    "            category_count = int(y_train.nunique())\n",
    "            print(f'\\n****** Evaluation result {variable_name} as dependent variable ******')\n",
    "            # For binary class classification \n",
    "            if category_count == 2:\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, average='binary')\n",
    "                recall = recall_score(y_test, y_pred, average='binary')\n",
    "                f1 = f1_score(y_test, y_pred, average='binary')\n",
    "                \n",
    "                print(f\"Accuracy: {accuracy}\")\n",
    "                print(f\"Precision: {precision}\")\n",
    "                print(f\"Recall: {recall}\")\n",
    "                print(f\"F1score: {f1}\")\n",
    "                print(\"Confused matrix:\")\n",
    "                conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                tn, fp, fn, tp = conf_matrix.ravel()\n",
    "                print(conf_matrix)\n",
    "                print(f\"True Negative (TN): {tn}\")\n",
    "                print(f\"False Positive (FP): {fp}\")\n",
    "                print(f\"False Negative (FN): {fn}\")\n",
    "                print(f\"True Positive (TP): {tp}\")\n",
    "                print(classification_report(y_test, y_pred))\n",
    "            \n",
    "            # For binary class classification \n",
    "            else:\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, average='weighted')\n",
    "                recall = recall_score(y_test, y_pred, average='weighted')\n",
    "                f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "                \n",
    "                print(f\"Accuracy: {accuracy}\")\n",
    "                print(f\"Precision: {precision}\")\n",
    "                print(f\"Recall: {recall}\")\n",
    "                print(f\"F1score: {f1}\")\n",
    "                conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                print(\"Confused matrix:\")\n",
    "                print(conf_matrix)\n",
    "                print(classification_report(y_test, y_pred))\n",
    "                \n",
    "    def prediction_with_medication_diagnosis(self):\n",
    "        # Select all corresponding columns with values in TNE_NO_365\n",
    "        self.merged_df = self.merged_df.dropna(subset=['TNE_NO_365'])\n",
    "        \n",
    "        # define dependent variables\n",
    "        self.dependent_variable_TNE_NO_365 = self.merged_df[['TNE_NO_365']]\n",
    "        # define independent variables \n",
    "        self.independent_variable = self.merged_df[['num_diagnoses', 'num_medications', 'remaining_time_countdown', 'var_no_dates_permonth','Length_of_Episode', 'Count_visit', 'Therapy_ratio','Examination_ratio', 'Advisory_ratio',\n",
    "        'TreatmentPlanning_ratio','Outpatient_ratio','Inpatient_daynight_ratio', 'Care_intensity', 'closingcode_0', 'closingcode_1', 'closingcode_2', 'closingcode_3','closingcode_4', 'closingcode_5', 'closingcode_6', 'closingcode_9',\n",
    "        'aftercode_1', 'aftercode_2', 'aftercode_3', 'aftercode_4','aftercode_5', 'gender_0', 'F', 'M', 'MiddleChildhood', 'Preschooler','Teenager',\n",
    "        '010', '0703', '0704', '079', '0792', '1000', '1008',\n",
    "       '1009', '1011', '1013', '1015', '136', '1499', '1551', '1701', '1702',\n",
    "       '18911', '1911', '19111', '1994', '201', '2022', '20411', '20421',\n",
    "       '2441', '2442', '2444', '2445', '24521', '2501', '25011', '2502',\n",
    "       '2531', '25311', '2532', '2553', '2564', '259', '260', '2602', '2612',\n",
    "       '2614', '262', '2701', '2713', '27614', '2781', '2791', '2801', '28731',\n",
    "       '288', '28811', '2903', '2911', '2914', '2922', '295', '2951', '2952',\n",
    "       '2953', '296', '2961', '29622', '2972', '300', '3001', '3003', '3004',\n",
    "       '3008', '3009', '301', '3011', '3012', '302', '303', '3031', '3033',\n",
    "       '3034', '304', '3052', '306', '3069', '312', '3123', '313', '3131',\n",
    "       '3132', '3133', '315', '3151', '3152', '3153', '316', '317', '323',\n",
    "       '324', '327', '3274', '32741', '3275', '3276', '3311', '339', '340',\n",
    "       '3401', '341', '343', '344', '345', '3451', '34511', '34512', '3453',\n",
    "       '347', '3484', '357', '3591', '3592', '3621', '365', '3671', '3672',\n",
    "       '3678', '3679', '368', '3681', '3684', '3695', '3711', '3781', '3782',\n",
    "       '3811', '389', '3891', '3892', '3894', '3895', '42711', '4332', '4338',\n",
    "       '4589', '472', '4741', '4742', '476', '4801', '495', '496', '499',\n",
    "       '506', '5091', '510', '53011', '53014', '5302', '5305', '535', '5551',\n",
    "       '5552', '55521', '558', '5611', '563', '564', '5641', '565', '57181',\n",
    "       '5772', '591', '5921', '5965', '5994', '6041', '62611', '6264', '637',\n",
    "       '6491', '656', '6562', '6563', '6564', '657', '658', '661', '691',\n",
    "       '6941', '69542', '6964', '7061', '71011', '7142', '7169', '7282',\n",
    "       '7321', '733', '736', '7373', '739', '745', '7471', '74711', '74712',\n",
    "       '74713', '7472', '748', '749', '7491', '7492', '75011', '75013',\n",
    "       '75021', '75112', '7512', '75121', '75211', '7522', '7531', '7551',\n",
    "       '7554', '7556', '75561', '756', '7561', '758', '7581', '759', '760',\n",
    "       '770', '773', '7981', '8003', '802', '8032', '8033', '805', '817',\n",
    "       '818', '819', '830', '835', '871', '907', '915', '930', '939', '946',\n",
    "       '947', '949', '969', '979', '981', 'A02B', 'A03F', 'A06A', 'A06B',\n",
    "       'A07A', 'A10B', 'A11E', 'A12A', 'A12B', 'B03A', 'B03B', 'C02A', 'C07A',\n",
    "       'C09A', 'D01A', 'D06A', 'D06B', 'D07A', 'D07B', 'D07X', 'D09A', 'D10A',\n",
    "       'G03A', 'G03C', 'G03F', 'G03H', 'H01B', 'H02A', 'J01C', 'J01F', 'J05A',\n",
    "       'M01A', 'N01B', 'N02A', 'N02B', 'N02C', 'N03A', 'N05A', 'N05B', 'N05C',\n",
    "       'N06A', 'N06B', 'N07B', 'NO6B', 'R01A', 'R03A', 'R03B', 'R05D', 'R06A',\n",
    "       'S01A', 'S01G']]\n",
    "        \n",
    "        dependent_variables = [self.dependent_variable_TNE_NO_365]\n",
    "        dependent_variable_names = {'self.dependent_variable_TNE_NO_365':'TNE_NO_365'}\n",
    "        #for dependent_variable in dependent_variables:\n",
    "        for variable_name, dependent_variable in zip(dependent_variable_names.values(), dependent_variables):\n",
    "            linear_prediction_model = LinearRegression()\n",
    "            X_train, X_temp, y_train, y_temp = train_test_split(self.independent_variable, dependent_variable, train_size=0.7)\n",
    "            X_test,X_eval,y_test,y_eval = train_test_split(X_temp,y_temp,test_size=0.33)\n",
    "            linear_prediction_model.fit(X_train,y_train)\n",
    "            y_pred = linear_prediction_model.predict(X_test)\n",
    "            print(f'\\n****** Prediction Model Evaluation result  {variable_name} as dependent variable ******')\n",
    "            y_pred = linear_prediction_model.predict(X_test)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            print('R-squared:', r2)\n",
    "            print('Mean squared error:', mse)\n",
    "                \n",
    "\n",
    "SplitMedicationDiagnosisInUniquePieces_Obj = SplitMedicationDiagnosisInUniquePieces(os.getenv(\"FILE_Full_Phecode_ATC_PATH\"))\n",
    "SplitMedicationDiagnosisInUniquePieces_Obj.split_diagnosis_medication_in_unique_pieces()\n",
    "\n",
    "ClassifyReadmissionWithMedicationDiagnosis_Obj = ClassifyReadmissionWithMedicationDiagnosis('Split_Full_Phecode_ATC4.csv')\n",
    "merged_df, dependent_variable_TNE_BO_365, independent_variable  = ClassifyReadmissionWithMedicationDiagnosis_Obj.load_data()\n",
    "ClassifyReadmissionWithMedicationDiagnosis_Obj.train_classifier_with_medication_diagnosis()\n",
    "ClassifyReadmissionWithMedicationDiagnosis_Obj.prediction_with_medication_diagnosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8b3085-1dc6-4a5c-bd34-f6b82ace5572",
   "metadata": {},
   "source": [
    "##### 3. Classify and Predict for 2 year\n",
    "\n",
    "**`TNE_BO_730` values (0 and 1 are used to classify readmission, where 1 means readmission). Further for prediction only the readmitted patient data is taken and a linear regression model is trained on it to predict the number of days for readmission.**\n",
    "- Dataset Used: `/mnt/work/workbench/dipendrp/new-data/Full_Phecode_ATC4.csv`\n",
    "- Independent variable: `'age', 'remaining_time_countdown','var_no_dates_permonth', 'gender','closingcode', 'aftercode', 'Length_of_Episode', \n",
    "                        'Count_visit','Therapy_ratio', 'Examination_ratio', 'Advisory_ratio','TreatmentPlanning_ratio', 'Outpatient_ratio',\n",
    "                        'Inpatient_daynight_ratio', 'Care_intensity', 'num_diagnoses', 'num_medications', \n",
    "                        and unique 'actual_diag_Phe', 'actual_med_ATC4'`\n",
    "- Dependent Variable: For classification its `TNE_BO_730` and for prediction its `TNE_NO_730`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301e8e3a-3fb6-4f84-8347-1e5299d9beaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import display\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score,confusion_matrix,precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "######### Split Medication and Diagnosis In Unique Pieces ############\n",
    "#                                                                    #\n",
    "#                                                                    #\n",
    "#                                                                    #\n",
    "######################################################################\n",
    "\n",
    "class SplitMedicationDiagnosisInUniquePieces:\n",
    "    def __init__(self, file1):\n",
    "        self.file1 = file1\n",
    "        self.merged_df = None\n",
    "        self.selected_column_merged_df = None\n",
    "        self.without_diag_medic_selected_column_merged_df = None\n",
    "    \n",
    "    def load_data_to_split(self):\n",
    "        Full_Phecode_ATC4 = pd.read_csv(self.file1)\n",
    "        self.merged_df = Full_Phecode_ATC4\n",
    "        # Specify the names of columns you are interested in here diagnosis and medication column name in the CSV files\n",
    "        self.merged_df = self.merged_df[['episode_id', 'num_diagnoses', 'num_medications', 'pasient', 'age',\n",
    "                                       'remaining_time_countdown', 'var_no_dates_permonth', 'gender',\n",
    "                                       'episode_order', 'islast', 'closingcode', 'aftercode',\n",
    "                                       'episode_start_date', 'episode_end_date', 'tillnextepisode',\n",
    "                                       'Length_of_Episode', 'Cat_LOE', 'TNE_BO_180', 'TNE_NO_180',\n",
    "                                       'TNE_BO_365', 'TNE_NO_365', 'TNE_BO_730', 'TNE_NO_730', 'TNE_BO_1095',\n",
    "                                       'TNE_NO_1095', 'Cat_LOE_desc', 'Count_visit', 'Cat_CV', 'Therapy_ratio',\n",
    "                                       'Examination_ratio', 'Advisory_ratio', 'TreatmentPlanning_ratio',\n",
    "                                       'Outpatient_ratio', 'Inpatient_ratio', 'Inpatient_day_ratio',\n",
    "                                       'Inpatient_daynight_ratio', 'Care_intensity', 'age_group',\n",
    "                                       'closingcode_0', 'closingcode_1', 'closingcode_2', 'closingcode_3',\n",
    "                                       'closingcode_4', 'closingcode_5', 'closingcode_6', 'closingcode_9',\n",
    "                                       'aftercode_1', 'aftercode_2', 'aftercode_3', 'aftercode_4',\n",
    "                                       'aftercode_5', 'gender_0', 'F', 'M', 'MiddleChildhood', 'Preschooler',\n",
    "                                       'Teenager', 'actual_diag_Phe', 'actual_med_ATC4']]\n",
    "        \n",
    "        self.merged_df = self.merged_df.copy(deep=True)\n",
    "        return self.merged_df\n",
    "\n",
    "        \n",
    "    def split_diagnosis_medication_in_unique_pieces(self):\n",
    "        newmerged_df = SplitMedicationDiagnosisInUniquePieces_Obj.load_data_to_split()\n",
    "        # Specify the exact names of diagnosis and medication column to perform the split\n",
    "        columns = ['actual_diag_Phe', 'actual_med_ATC4']\n",
    "        for col in columns:\n",
    "            newmerged_df[col] = newmerged_df[col].apply(lambda d:[] if pd.isnull(d) else d)\n",
    "            newmerged_df[col] = newmerged_df[col].str.replace(\"[\", \"\")\n",
    "            newmerged_df[col] = newmerged_df[col].str.replace(\"]\", \"\")\n",
    "            newmerged_df[col] = newmerged_df[col].str.replace(\"'\", \"\")\n",
    "            newmerged_df[col] = newmerged_df[col].str.replace(\" \", \"\")\n",
    "            newmerged_df[col] = newmerged_df[col].str.split(',')\n",
    "            newmerged_df = newmerged_df.explode(col)\n",
    "            \n",
    "            # Show only top 100 columns names\n",
    "            temp_store_100 = newmerged_df[col].value_counts()\n",
    "            names_only = temp_store_100.index.tolist()\n",
    "            \n",
    "            original_columns = newmerged_df.columns.tolist()\n",
    "            dummies = newmerged_df[col].str.get_dummies(sep=',')\n",
    "            newmerged_df = pd.concat([newmerged_df, dummies], axis=1)\n",
    "            newmerged_df = newmerged_df.drop(col, axis=1)\n",
    "            \n",
    "        newmerged_df.to_csv('Split_Full_Phecode_ATC4.csv',index=False)\n",
    "        \n",
    "    \n",
    "class ClassifyReadmissionWithMedicationDiagnosis:\n",
    "    def __init__(self, file2):\n",
    "        self.file2 = file2\n",
    "        self.merged_df = None\n",
    "        self.selected_column_merged_df = None\n",
    "        self.without_diag_medic_selected_column_merged_df = None\n",
    "    \n",
    "    def load_data(self):\n",
    "        original_df_1 = pd.read_csv(self.file2)\n",
    "        self.merged_df = original_df_1[['num_diagnoses', 'num_medications', 'remaining_time_countdown', 'var_no_dates_permonth','Length_of_Episode', 'Count_visit', 'Therapy_ratio','Examination_ratio', 'Advisory_ratio',\n",
    "        'TreatmentPlanning_ratio','Outpatient_ratio','Inpatient_daynight_ratio', 'Care_intensity', 'closingcode_0', 'closingcode_1', 'closingcode_2', 'closingcode_3','closingcode_4', 'closingcode_5', 'closingcode_6', 'closingcode_9',\n",
    "        'aftercode_1', 'aftercode_2', 'aftercode_3', 'aftercode_4','aftercode_5', 'gender_0', 'F', 'M', 'MiddleChildhood', 'Preschooler','Teenager', 'TNE_NO_730','TNE_BO_730',\n",
    "        '010', '0703', '0704', '079', '0792', '1000', '1008',\n",
    "       '1009', '1011', '1013', '1015', '136', '1499', '1551', '1701', '1702',\n",
    "       '18911', '1911', '19111', '1994', '201', '2022', '20411', '20421',\n",
    "       '2441', '2442', '2444', '2445', '24521', '2501', '25011', '2502',\n",
    "       '2531', '25311', '2532', '2553', '2564', '259', '260', '2602', '2612',\n",
    "       '2614', '262', '2701', '2713', '27614', '2781', '2791', '2801', '28731',\n",
    "       '288', '28811', '2903', '2911', '2914', '2922', '295', '2951', '2952',\n",
    "       '2953', '296', '2961', '29622', '2972', '300', '3001', '3003', '3004',\n",
    "       '3008', '3009', '301', '3011', '3012', '302', '303', '3031', '3033',\n",
    "       '3034', '304', '3052', '306', '3069', '312', '3123', '313', '3131',\n",
    "       '3132', '3133', '315', '3151', '3152', '3153', '316', '317', '323',\n",
    "       '324', '327', '3274', '32741', '3275', '3276', '3311', '339', '340',\n",
    "       '3401', '341', '343', '344', '345', '3451', '34511', '34512', '3453',\n",
    "       '347', '3484', '357', '3591', '3592', '3621', '365', '3671', '3672',\n",
    "       '3678', '3679', '368', '3681', '3684', '3695', '3711', '3781', '3782',\n",
    "       '3811', '389', '3891', '3892', '3894', '3895', '42711', '4332', '4338',\n",
    "       '4589', '472', '4741', '4742', '476', '4801', '495', '496', '499',\n",
    "       '506', '5091', '510', '53011', '53014', '5302', '5305', '535', '5551',\n",
    "       '5552', '55521', '558', '5611', '563', '564', '5641', '565', '57181',\n",
    "       '5772', '591', '5921', '5965', '5994', '6041', '62611', '6264', '637',\n",
    "       '6491', '656', '6562', '6563', '6564', '657', '658', '661', '691',\n",
    "       '6941', '69542', '6964', '7061', '71011', '7142', '7169', '7282',\n",
    "       '7321', '733', '736', '7373', '739', '745', '7471', '74711', '74712',\n",
    "       '74713', '7472', '748', '749', '7491', '7492', '75011', '75013',\n",
    "       '75021', '75112', '7512', '75121', '75211', '7522', '7531', '7551',\n",
    "       '7554', '7556', '75561', '756', '7561', '758', '7581', '759', '760',\n",
    "       '770', '773', '7981', '8003', '802', '8032', '8033', '805', '817',\n",
    "       '818', '819', '830', '835', '871', '907', '915', '930', '939', '946',\n",
    "       '947', '949', '969', '979', '981', 'A02B', 'A03F', 'A06A', 'A06B',\n",
    "       'A07A', 'A10B', 'A11E', 'A12A', 'A12B', 'B03A', 'B03B', 'C02A', 'C07A',\n",
    "       'C09A', 'D01A', 'D06A', 'D06B', 'D07A', 'D07B', 'D07X', 'D09A', 'D10A',\n",
    "       'G03A', 'G03C', 'G03F', 'G03H', 'H01B', 'H02A', 'J01C', 'J01F', 'J05A',\n",
    "       'M01A', 'N01B', 'N02A', 'N02B', 'N02C', 'N03A', 'N05A', 'N05B', 'N05C',\n",
    "       'N06A', 'N06B', 'N07B', 'NO6B', 'R01A', 'R03A', 'R03B', 'R05D', 'R06A',\n",
    "       'S01A', 'S01G']]\n",
    "        \n",
    "        \n",
    "       \n",
    "        # fill nan values in independent column\n",
    "        self.merged_df['num_diagnoses'].fillna(0, inplace=True)\n",
    "        self.merged_df['num_medications'].fillna(0, inplace=True)\n",
    "        self.merged_df['Outpatient_ratio'].fillna(0, inplace=True)\n",
    "        self.merged_df['Inpatient_daynight_ratio'].fillna(0, inplace=True)  \n",
    "        self.merged_df['Therapy_ratio'].fillna(0, inplace=True)\n",
    "        self.merged_df['Examination_ratio'].fillna(0, inplace=True)\n",
    "        self.merged_df['Advisory_ratio'].fillna(0, inplace=True)\n",
    "        self.merged_df['TreatmentPlanning_ratio'].fillna(0, inplace=True)\n",
    "        \n",
    "        \n",
    "        # define dependent variables\n",
    "        self.dependent_variable_TNE_BO_730 = self.merged_df[['TNE_BO_730']]\n",
    "        \n",
    "        self.independent_variable = self.merged_df[['num_diagnoses', 'num_medications', 'remaining_time_countdown', 'var_no_dates_permonth','Length_of_Episode', 'Count_visit', 'Therapy_ratio','Examination_ratio', 'Advisory_ratio',\n",
    "        'TreatmentPlanning_ratio','Outpatient_ratio','Inpatient_daynight_ratio', 'Care_intensity', 'closingcode_0', 'closingcode_1', 'closingcode_2', 'closingcode_3','closingcode_4', 'closingcode_5', 'closingcode_6', 'closingcode_9',\n",
    "        'aftercode_1', 'aftercode_2', 'aftercode_3', 'aftercode_4','aftercode_5', 'gender_0', 'F', 'M', 'MiddleChildhood', 'Preschooler','Teenager',\n",
    "        '010', '0703', '0704', '079', '0792', '1000', '1008',\n",
    "       '1009', '1011', '1013', '1015', '136', '1499', '1551', '1701', '1702',\n",
    "       '18911', '1911', '19111', '1994', '201', '2022', '20411', '20421',\n",
    "       '2441', '2442', '2444', '2445', '24521', '2501', '25011', '2502',\n",
    "       '2531', '25311', '2532', '2553', '2564', '259', '260', '2602', '2612',\n",
    "       '2614', '262', '2701', '2713', '27614', '2781', '2791', '2801', '28731',\n",
    "       '288', '28811', '2903', '2911', '2914', '2922', '295', '2951', '2952',\n",
    "       '2953', '296', '2961', '29622', '2972', '300', '3001', '3003', '3004',\n",
    "       '3008', '3009', '301', '3011', '3012', '302', '303', '3031', '3033',\n",
    "       '3034', '304', '3052', '306', '3069', '312', '3123', '313', '3131',\n",
    "       '3132', '3133', '315', '3151', '3152', '3153', '316', '317', '323',\n",
    "       '324', '327', '3274', '32741', '3275', '3276', '3311', '339', '340',\n",
    "       '3401', '341', '343', '344', '345', '3451', '34511', '34512', '3453',\n",
    "       '347', '3484', '357', '3591', '3592', '3621', '365', '3671', '3672',\n",
    "       '3678', '3679', '368', '3681', '3684', '3695', '3711', '3781', '3782',\n",
    "       '3811', '389', '3891', '3892', '3894', '3895', '42711', '4332', '4338',\n",
    "       '4589', '472', '4741', '4742', '476', '4801', '495', '496', '499',\n",
    "       '506', '5091', '510', '53011', '53014', '5302', '5305', '535', '5551',\n",
    "       '5552', '55521', '558', '5611', '563', '564', '5641', '565', '57181',\n",
    "       '5772', '591', '5921', '5965', '5994', '6041', '62611', '6264', '637',\n",
    "       '6491', '656', '6562', '6563', '6564', '657', '658', '661', '691',\n",
    "       '6941', '69542', '6964', '7061', '71011', '7142', '7169', '7282',\n",
    "       '7321', '733', '736', '7373', '739', '745', '7471', '74711', '74712',\n",
    "       '74713', '7472', '748', '749', '7491', '7492', '75011', '75013',\n",
    "       '75021', '75112', '7512', '75121', '75211', '7522', '7531', '7551',\n",
    "       '7554', '7556', '75561', '756', '7561', '758', '7581', '759', '760',\n",
    "       '770', '773', '7981', '8003', '802', '8032', '8033', '805', '817',\n",
    "       '818', '819', '830', '835', '871', '907', '915', '930', '939', '946',\n",
    "       '947', '949', '969', '979', '981', 'A02B', 'A03F', 'A06A', 'A06B',\n",
    "       'A07A', 'A10B', 'A11E', 'A12A', 'A12B', 'B03A', 'B03B', 'C02A', 'C07A',\n",
    "       'C09A', 'D01A', 'D06A', 'D06B', 'D07A', 'D07B', 'D07X', 'D09A', 'D10A',\n",
    "       'G03A', 'G03C', 'G03F', 'G03H', 'H01B', 'H02A', 'J01C', 'J01F', 'J05A',\n",
    "       'M01A', 'N01B', 'N02A', 'N02B', 'N02C', 'N03A', 'N05A', 'N05B', 'N05C',\n",
    "       'N06A', 'N06B', 'N07B', 'NO6B', 'R01A', 'R03A', 'R03B', 'R05D', 'R06A',\n",
    "       'S01A', 'S01G']]\n",
    "        \n",
    "        return self.merged_df, self.dependent_variable_TNE_BO_730, self.independent_variable \n",
    "    \n",
    "    # To train and view the reasult of binary and multiclass classifier        \n",
    "    def train_classifier_with_medication_diagnosis(self):\n",
    "        dependent_variables = [self.dependent_variable_TNE_BO_730]\n",
    "        \n",
    "        # to define the weight of output class, to resolve imbalanced output/dataset\n",
    "        dependent_variable_names = {'self.dependent_variable_TNE_BO_730': 'TNE_BO_730'}\n",
    "        class_weights = {'TNE_BO_730': {0:10, 1:270}}\n",
    "              \n",
    "        #for dependent_variable in dependent_variables:\n",
    "        for variable_name, dependent_variable in zip(dependent_variable_names.values(), dependent_variables):\n",
    "            logistic_prediction_model = LogisticRegression(class_weight=class_weights[variable_name])\n",
    "            X_train, X_test, y_train, y_test = train_test_split(self.independent_variable, dependent_variable, train_size=0.7)\n",
    "            logistic_prediction_model.fit(X_train,y_train)\n",
    "            y_pred = logistic_prediction_model.predict(X_test)\n",
    "            \n",
    "            # Checks if the output category for classification is binary or multiclass\n",
    "            category_count = int(y_train.nunique())\n",
    "            print(f'\\n****** Evaluation result {variable_name} as dependent variable ******')\n",
    "            # For binary class classification \n",
    "            if category_count == 2:\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, average='binary')\n",
    "                recall = recall_score(y_test, y_pred, average='binary')\n",
    "                f1 = f1_score(y_test, y_pred, average='binary')\n",
    "                \n",
    "                print(f\"Accuracy: {accuracy}\")\n",
    "                print(f\"Precision: {precision}\")\n",
    "                print(f\"Recall: {recall}\")\n",
    "                print(f\"F1score: {f1}\")\n",
    "                print(\"Confused matrix:\")\n",
    "                conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                tn, fp, fn, tp = conf_matrix.ravel()\n",
    "                print(conf_matrix)\n",
    "                print(f\"True Negative (TN): {tn}\")\n",
    "                print(f\"False Positive (FP): {fp}\")\n",
    "                print(f\"False Negative (FN): {fn}\")\n",
    "                print(f\"True Positive (TP): {tp}\")\n",
    "                print(classification_report(y_test, y_pred))\n",
    "            \n",
    "            # For binary class classification \n",
    "            else:\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, average='weighted')\n",
    "                recall = recall_score(y_test, y_pred, average='weighted')\n",
    "                f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "                \n",
    "                print(f\"Accuracy: {accuracy}\")\n",
    "                print(f\"Precision: {precision}\")\n",
    "                print(f\"Recall: {recall}\")\n",
    "                print(f\"F1score: {f1}\")\n",
    "                conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                print(\"Confused matrix:\")\n",
    "                print(conf_matrix)\n",
    "                print(classification_report(y_test, y_pred))\n",
    "                \n",
    "    def prediction_with_medication_diagnosis(self):\n",
    "        # Select all corresponding columns with values in TNE_NO_730\n",
    "        self.merged_df = self.merged_df.dropna(subset=['TNE_NO_730'])\n",
    "        \n",
    "        # define dependent variables\n",
    "        self.dependent_variable_TNE_NO_730 = self.merged_df[['TNE_NO_730']]\n",
    "        # define independent variables \n",
    "        self.independent_variable = self.merged_df[['num_diagnoses', 'num_medications', 'remaining_time_countdown', 'var_no_dates_permonth','Length_of_Episode', 'Count_visit', 'Therapy_ratio','Examination_ratio', 'Advisory_ratio',\n",
    "        'TreatmentPlanning_ratio','Outpatient_ratio','Inpatient_daynight_ratio', 'Care_intensity', 'closingcode_0', 'closingcode_1', 'closingcode_2', 'closingcode_3','closingcode_4', 'closingcode_5', 'closingcode_6', 'closingcode_9',\n",
    "        'aftercode_1', 'aftercode_2', 'aftercode_3', 'aftercode_4','aftercode_5', 'gender_0', 'F', 'M', 'MiddleChildhood', 'Preschooler','Teenager',\n",
    "        '010', '0703', '0704', '079', '0792', '1000', '1008',\n",
    "       '1009', '1011', '1013', '1015', '136', '1499', '1551', '1701', '1702',\n",
    "       '18911', '1911', '19111', '1994', '201', '2022', '20411', '20421',\n",
    "       '2441', '2442', '2444', '2445', '24521', '2501', '25011', '2502',\n",
    "       '2531', '25311', '2532', '2553', '2564', '259', '260', '2602', '2612',\n",
    "       '2614', '262', '2701', '2713', '27614', '2781', '2791', '2801', '28731',\n",
    "       '288', '28811', '2903', '2911', '2914', '2922', '295', '2951', '2952',\n",
    "       '2953', '296', '2961', '29622', '2972', '300', '3001', '3003', '3004',\n",
    "       '3008', '3009', '301', '3011', '3012', '302', '303', '3031', '3033',\n",
    "       '3034', '304', '3052', '306', '3069', '312', '3123', '313', '3131',\n",
    "       '3132', '3133', '315', '3151', '3152', '3153', '316', '317', '323',\n",
    "       '324', '327', '3274', '32741', '3275', '3276', '3311', '339', '340',\n",
    "       '3401', '341', '343', '344', '345', '3451', '34511', '34512', '3453',\n",
    "       '347', '3484', '357', '3591', '3592', '3621', '365', '3671', '3672',\n",
    "       '3678', '3679', '368', '3681', '3684', '3695', '3711', '3781', '3782',\n",
    "       '3811', '389', '3891', '3892', '3894', '3895', '42711', '4332', '4338',\n",
    "       '4589', '472', '4741', '4742', '476', '4801', '495', '496', '499',\n",
    "       '506', '5091', '510', '53011', '53014', '5302', '5305', '535', '5551',\n",
    "       '5552', '55521', '558', '5611', '563', '564', '5641', '565', '57181',\n",
    "       '5772', '591', '5921', '5965', '5994', '6041', '62611', '6264', '637',\n",
    "       '6491', '656', '6562', '6563', '6564', '657', '658', '661', '691',\n",
    "       '6941', '69542', '6964', '7061', '71011', '7142', '7169', '7282',\n",
    "       '7321', '733', '736', '7373', '739', '745', '7471', '74711', '74712',\n",
    "       '74713', '7472', '748', '749', '7491', '7492', '75011', '75013',\n",
    "       '75021', '75112', '7512', '75121', '75211', '7522', '7531', '7551',\n",
    "       '7554', '7556', '75561', '756', '7561', '758', '7581', '759', '760',\n",
    "       '770', '773', '7981', '8003', '802', '8032', '8033', '805', '817',\n",
    "       '818', '819', '830', '835', '871', '907', '915', '930', '939', '946',\n",
    "       '947', '949', '969', '979', '981', 'A02B', 'A03F', 'A06A', 'A06B',\n",
    "       'A07A', 'A10B', 'A11E', 'A12A', 'A12B', 'B03A', 'B03B', 'C02A', 'C07A',\n",
    "       'C09A', 'D01A', 'D06A', 'D06B', 'D07A', 'D07B', 'D07X', 'D09A', 'D10A',\n",
    "       'G03A', 'G03C', 'G03F', 'G03H', 'H01B', 'H02A', 'J01C', 'J01F', 'J05A',\n",
    "       'M01A', 'N01B', 'N02A', 'N02B', 'N02C', 'N03A', 'N05A', 'N05B', 'N05C',\n",
    "       'N06A', 'N06B', 'N07B', 'NO6B', 'R01A', 'R03A', 'R03B', 'R05D', 'R06A',\n",
    "       'S01A', 'S01G']]\n",
    "        \n",
    "        dependent_variables = [self.dependent_variable_TNE_NO_730]\n",
    "        dependent_variable_names = {'self.dependent_variable_TNE_NO_730':'TNE_NO_730'}\n",
    "        #for dependent_variable in dependent_variables:\n",
    "        for variable_name, dependent_variable in zip(dependent_variable_names.values(), dependent_variables):\n",
    "            linear_prediction_model = LinearRegression()\n",
    "            X_train, X_temp, y_train, y_temp = train_test_split(self.independent_variable, dependent_variable, train_size=0.7)\n",
    "            X_test,X_eval,y_test,y_eval = train_test_split(X_temp,y_temp,test_size=0.33)\n",
    "            linear_prediction_model.fit(X_train,y_train)\n",
    "            y_pred = linear_prediction_model.predict(X_test)\n",
    "            print(f'\\n****** Prediction Model Evaluation result  {variable_name} as dependent variable ******')\n",
    "            y_pred = linear_prediction_model.predict(X_test)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            print('R-squared:', r2)\n",
    "            print('Mean squared error:', mse)\n",
    "                \n",
    "\n",
    "SplitMedicationDiagnosisInUniquePieces_Obj = SplitMedicationDiagnosisInUniquePieces(os.getenv(\"FILE_Full_Phecode_ATC_PATH\"))\n",
    "SplitMedicationDiagnosisInUniquePieces_Obj.split_diagnosis_medication_in_unique_pieces()\n",
    "\n",
    "ClassifyReadmissionWithMedicationDiagnosis_Obj = ClassifyReadmissionWithMedicationDiagnosis('Split_Full_Phecode_ATC4.csv')\n",
    "merged_df, dependent_variable_TNE_BO_730, independent_variable  = ClassifyReadmissionWithMedicationDiagnosis_Obj.load_data()\n",
    "ClassifyReadmissionWithMedicationDiagnosis_Obj.train_classifier_with_medication_diagnosis()\n",
    "ClassifyReadmissionWithMedicationDiagnosis_Obj.prediction_with_medication_diagnosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1911fe12-8054-421f-a43b-9a972a4e3583",
   "metadata": {},
   "source": [
    "##### 4. Classify and Predict for 3 year\n",
    "\n",
    "**`TNE_BO_1095` values (0 and 1 are used to classify readmission, where 1 means readmission). Further for prediction only the readmitted patient data is taken and a linear regression model is trained on it to predict the number of days for readmission.**\n",
    "- Dataset Used: `/mnt/work/workbench/dipendrp/new-data/Full_Phecode_ATC4.csv`\n",
    "- Independent variable: `'age', 'remaining_time_countdown','var_no_dates_permonth', 'gender','closingcode', 'aftercode', 'Length_of_Episode', \n",
    "                        'Count_visit','Therapy_ratio', 'Examination_ratio', 'Advisory_ratio','TreatmentPlanning_ratio', 'Outpatient_ratio',\n",
    "                        'Inpatient_daynight_ratio', 'Care_intensity', 'num_diagnoses', 'num_medications', \n",
    "                        and unique 'actual_diag_Phe', 'actual_med_ATC4'`\n",
    "- Dependent Variable: For classification its `TNE_BO_1095` and for prediction its `TNE_NO_1095`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359a0965-8bd3-46ec-92ad-2d4013198fb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import display\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score,confusion_matrix,precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "######### Split Medication and Diagnosis In Unique Pieces ############\n",
    "#                                                                    #\n",
    "#                                                                    #\n",
    "#                                                                    #\n",
    "######################################################################\n",
    "\n",
    "class SplitMedicationDiagnosisInUniquePieces:\n",
    "    def __init__(self, file1):\n",
    "        self.file1 = file1\n",
    "        self.merged_df = None\n",
    "        self.selected_column_merged_df = None\n",
    "        self.without_diag_medic_selected_column_merged_df = None\n",
    "    \n",
    "    def load_data_to_split(self):\n",
    "        Full_Phecode_ATC4 = pd.read_csv(self.file1)\n",
    "        self.merged_df = Full_Phecode_ATC4\n",
    "        # Specify the names of columns you are interested in here diagnosis and medication column name in the CSV files\n",
    "        self.merged_df = self.merged_df[['episode_id', 'num_diagnoses', 'num_medications', 'pasient', 'age',\n",
    "                                       'remaining_time_countdown', 'var_no_dates_permonth', 'gender',\n",
    "                                       'episode_order', 'islast', 'closingcode', 'aftercode',\n",
    "                                       'episode_start_date', 'episode_end_date', 'tillnextepisode',\n",
    "                                       'Length_of_Episode', 'Cat_LOE', 'TNE_BO_180', 'TNE_NO_180',\n",
    "                                       'TNE_BO_365', 'TNE_NO_365', 'TNE_BO_730', 'TNE_NO_730', 'TNE_BO_1095',\n",
    "                                       'TNE_NO_1095', 'Cat_LOE_desc', 'Count_visit', 'Cat_CV', 'Therapy_ratio',\n",
    "                                       'Examination_ratio', 'Advisory_ratio', 'TreatmentPlanning_ratio',\n",
    "                                       'Outpatient_ratio', 'Inpatient_ratio', 'Inpatient_day_ratio',\n",
    "                                       'Inpatient_daynight_ratio', 'Care_intensity', 'age_group',\n",
    "                                       'closingcode_0', 'closingcode_1', 'closingcode_2', 'closingcode_3',\n",
    "                                       'closingcode_4', 'closingcode_5', 'closingcode_6', 'closingcode_9',\n",
    "                                       'aftercode_1', 'aftercode_2', 'aftercode_3', 'aftercode_4',\n",
    "                                       'aftercode_5', 'gender_0', 'F', 'M', 'MiddleChildhood', 'Preschooler',\n",
    "                                       'Teenager', 'actual_diag_Phe', 'actual_med_ATC4']]\n",
    "        \n",
    "        self.merged_df = self.merged_df.copy(deep=True)\n",
    "        return self.merged_df\n",
    "\n",
    "        \n",
    "    def split_diagnosis_medication_in_unique_pieces(self):\n",
    "        newmerged_df = SplitMedicationDiagnosisInUniquePieces_Obj.load_data_to_split()\n",
    "        # Specify the exact names of diagnosis and medication column to perform the split\n",
    "        columns = ['actual_diag_Phe', 'actual_med_ATC4']\n",
    "        for col in columns:\n",
    "            newmerged_df[col] = newmerged_df[col].apply(lambda d:[] if pd.isnull(d) else d)\n",
    "            newmerged_df[col] = newmerged_df[col].str.replace(\"[\", \"\")\n",
    "            newmerged_df[col] = newmerged_df[col].str.replace(\"]\", \"\")\n",
    "            newmerged_df[col] = newmerged_df[col].str.replace(\"'\", \"\")\n",
    "            newmerged_df[col] = newmerged_df[col].str.replace(\" \", \"\")\n",
    "            newmerged_df[col] = newmerged_df[col].str.split(',')\n",
    "            newmerged_df = newmerged_df.explode(col)\n",
    "            \n",
    "            # Show only top 100 columns names\n",
    "            temp_store_100 = newmerged_df[col].value_counts()\n",
    "            names_only = temp_store_100.index.tolist()\n",
    "            \n",
    "            original_columns = newmerged_df.columns.tolist()\n",
    "            dummies = newmerged_df[col].str.get_dummies(sep=',')\n",
    "            newmerged_df = pd.concat([newmerged_df, dummies], axis=1)\n",
    "            newmerged_df = newmerged_df.drop(col, axis=1)\n",
    "            \n",
    "        newmerged_df.to_csv('Split_Full_Phecode_ATC4.csv',index=False)\n",
    "        \n",
    "    \n",
    "class ClassifyReadmissionWithMedicationDiagnosis:\n",
    "    def __init__(self, file2):\n",
    "        self.file2 = file2\n",
    "        self.merged_df = None\n",
    "        self.selected_column_merged_df = None\n",
    "        self.without_diag_medic_selected_column_merged_df = None\n",
    "    \n",
    "    def load_data(self):\n",
    "        original_df_1 = pd.read_csv(self.file2)\n",
    "        self.merged_df = original_df_1[['num_diagnoses', 'num_medications', 'remaining_time_countdown', 'var_no_dates_permonth','Length_of_Episode', 'Count_visit', 'Therapy_ratio','Examination_ratio', 'Advisory_ratio',\n",
    "        'TreatmentPlanning_ratio','Outpatient_ratio','Inpatient_daynight_ratio', 'Care_intensity', 'closingcode_0', 'closingcode_1', 'closingcode_2', 'closingcode_3','closingcode_4', 'closingcode_5', 'closingcode_6', 'closingcode_9',\n",
    "        'aftercode_1', 'aftercode_2', 'aftercode_3', 'aftercode_4','aftercode_5', 'gender_0', 'F', 'M', 'MiddleChildhood', 'Preschooler','Teenager', 'TNE_NO_1095','TNE_BO_1095',\n",
    "        '010', '0703', '0704', '079', '0792', '1000', '1008',\n",
    "       '1009', '1011', '1013', '1015', '136', '1499', '1551', '1701', '1702',\n",
    "       '18911', '1911', '19111', '1994', '201', '2022', '20411', '20421',\n",
    "       '2441', '2442', '2444', '2445', '24521', '2501', '25011', '2502',\n",
    "       '2531', '25311', '2532', '2553', '2564', '259', '260', '2602', '2612',\n",
    "       '2614', '262', '2701', '2713', '27614', '2781', '2791', '2801', '28731',\n",
    "       '288', '28811', '2903', '2911', '2914', '2922', '295', '2951', '2952',\n",
    "       '2953', '296', '2961', '29622', '2972', '300', '3001', '3003', '3004',\n",
    "       '3008', '3009', '301', '3011', '3012', '302', '303', '3031', '3033',\n",
    "       '3034', '304', '3052', '306', '3069', '312', '3123', '313', '3131',\n",
    "       '3132', '3133', '315', '3151', '3152', '3153', '316', '317', '323',\n",
    "       '324', '327', '3274', '32741', '3275', '3276', '3311', '339', '340',\n",
    "       '3401', '341', '343', '344', '345', '3451', '34511', '34512', '3453',\n",
    "       '347', '3484', '357', '3591', '3592', '3621', '365', '3671', '3672',\n",
    "       '3678', '3679', '368', '3681', '3684', '3695', '3711', '3781', '3782',\n",
    "       '3811', '389', '3891', '3892', '3894', '3895', '42711', '4332', '4338',\n",
    "       '4589', '472', '4741', '4742', '476', '4801', '495', '496', '499',\n",
    "       '506', '5091', '510', '53011', '53014', '5302', '5305', '535', '5551',\n",
    "       '5552', '55521', '558', '5611', '563', '564', '5641', '565', '57181',\n",
    "       '5772', '591', '5921', '5965', '5994', '6041', '62611', '6264', '637',\n",
    "       '6491', '656', '6562', '6563', '6564', '657', '658', '661', '691',\n",
    "       '6941', '69542', '6964', '7061', '71011', '7142', '7169', '7282',\n",
    "       '7321', '733', '736', '7373', '739', '745', '7471', '74711', '74712',\n",
    "       '74713', '7472', '748', '749', '7491', '7492', '75011', '75013',\n",
    "       '75021', '75112', '7512', '75121', '75211', '7522', '7531', '7551',\n",
    "       '7554', '7556', '75561', '756', '7561', '758', '7581', '759', '760',\n",
    "       '770', '773', '7981', '8003', '802', '8032', '8033', '805', '817',\n",
    "       '818', '819', '830', '835', '871', '907', '915', '930', '939', '946',\n",
    "       '947', '949', '969', '979', '981', 'A02B', 'A03F', 'A06A', 'A06B',\n",
    "       'A07A', 'A10B', 'A11E', 'A12A', 'A12B', 'B03A', 'B03B', 'C02A', 'C07A',\n",
    "       'C09A', 'D01A', 'D06A', 'D06B', 'D07A', 'D07B', 'D07X', 'D09A', 'D10A',\n",
    "       'G03A', 'G03C', 'G03F', 'G03H', 'H01B', 'H02A', 'J01C', 'J01F', 'J05A',\n",
    "       'M01A', 'N01B', 'N02A', 'N02B', 'N02C', 'N03A', 'N05A', 'N05B', 'N05C',\n",
    "       'N06A', 'N06B', 'N07B', 'NO6B', 'R01A', 'R03A', 'R03B', 'R05D', 'R06A',\n",
    "       'S01A', 'S01G']]\n",
    "        \n",
    "        \n",
    "       \n",
    "        # fill nan values in independent column\n",
    "        self.merged_df['num_diagnoses'].fillna(0, inplace=True)\n",
    "        self.merged_df['num_medications'].fillna(0, inplace=True)\n",
    "        self.merged_df['Outpatient_ratio'].fillna(0, inplace=True)\n",
    "        self.merged_df['Inpatient_daynight_ratio'].fillna(0, inplace=True)  \n",
    "        self.merged_df['Therapy_ratio'].fillna(0, inplace=True)\n",
    "        self.merged_df['Examination_ratio'].fillna(0, inplace=True)\n",
    "        self.merged_df['Advisory_ratio'].fillna(0, inplace=True)\n",
    "        self.merged_df['TreatmentPlanning_ratio'].fillna(0, inplace=True)\n",
    "        \n",
    "        \n",
    "        # define dependent variables\n",
    "        self.dependent_variable_TNE_BO_1095 = self.merged_df[['TNE_BO_1095']]\n",
    "        \n",
    "        self.independent_variable = self.merged_df[['num_diagnoses', 'num_medications', 'remaining_time_countdown', 'var_no_dates_permonth','Length_of_Episode', 'Count_visit', 'Therapy_ratio','Examination_ratio', 'Advisory_ratio',\n",
    "        'TreatmentPlanning_ratio','Outpatient_ratio','Inpatient_daynight_ratio', 'Care_intensity', 'closingcode_0', 'closingcode_1', 'closingcode_2', 'closingcode_3','closingcode_4', 'closingcode_5', 'closingcode_6', 'closingcode_9',\n",
    "        'aftercode_1', 'aftercode_2', 'aftercode_3', 'aftercode_4','aftercode_5', 'gender_0', 'F', 'M', 'MiddleChildhood', 'Preschooler','Teenager',\n",
    "        '010', '0703', '0704', '079', '0792', '1000', '1008',\n",
    "       '1009', '1011', '1013', '1015', '136', '1499', '1551', '1701', '1702',\n",
    "       '18911', '1911', '19111', '1994', '201', '2022', '20411', '20421',\n",
    "       '2441', '2442', '2444', '2445', '24521', '2501', '25011', '2502',\n",
    "       '2531', '25311', '2532', '2553', '2564', '259', '260', '2602', '2612',\n",
    "       '2614', '262', '2701', '2713', '27614', '2781', '2791', '2801', '28731',\n",
    "       '288', '28811', '2903', '2911', '2914', '2922', '295', '2951', '2952',\n",
    "       '2953', '296', '2961', '29622', '2972', '300', '3001', '3003', '3004',\n",
    "       '3008', '3009', '301', '3011', '3012', '302', '303', '3031', '3033',\n",
    "       '3034', '304', '3052', '306', '3069', '312', '3123', '313', '3131',\n",
    "       '3132', '3133', '315', '3151', '3152', '3153', '316', '317', '323',\n",
    "       '324', '327', '3274', '32741', '3275', '3276', '3311', '339', '340',\n",
    "       '3401', '341', '343', '344', '345', '3451', '34511', '34512', '3453',\n",
    "       '347', '3484', '357', '3591', '3592', '3621', '365', '3671', '3672',\n",
    "       '3678', '3679', '368', '3681', '3684', '3695', '3711', '3781', '3782',\n",
    "       '3811', '389', '3891', '3892', '3894', '3895', '42711', '4332', '4338',\n",
    "       '4589', '472', '4741', '4742', '476', '4801', '495', '496', '499',\n",
    "       '506', '5091', '510', '53011', '53014', '5302', '5305', '535', '5551',\n",
    "       '5552', '55521', '558', '5611', '563', '564', '5641', '565', '57181',\n",
    "       '5772', '591', '5921', '5965', '5994', '6041', '62611', '6264', '637',\n",
    "       '6491', '656', '6562', '6563', '6564', '657', '658', '661', '691',\n",
    "       '6941', '69542', '6964', '7061', '71011', '7142', '7169', '7282',\n",
    "       '7321', '733', '736', '7373', '739', '745', '7471', '74711', '74712',\n",
    "       '74713', '7472', '748', '749', '7491', '7492', '75011', '75013',\n",
    "       '75021', '75112', '7512', '75121', '75211', '7522', '7531', '7551',\n",
    "       '7554', '7556', '75561', '756', '7561', '758', '7581', '759', '760',\n",
    "       '770', '773', '7981', '8003', '802', '8032', '8033', '805', '817',\n",
    "       '818', '819', '830', '835', '871', '907', '915', '930', '939', '946',\n",
    "       '947', '949', '969', '979', '981', 'A02B', 'A03F', 'A06A', 'A06B',\n",
    "       'A07A', 'A10B', 'A11E', 'A12A', 'A12B', 'B03A', 'B03B', 'C02A', 'C07A',\n",
    "       'C09A', 'D01A', 'D06A', 'D06B', 'D07A', 'D07B', 'D07X', 'D09A', 'D10A',\n",
    "       'G03A', 'G03C', 'G03F', 'G03H', 'H01B', 'H02A', 'J01C', 'J01F', 'J05A',\n",
    "       'M01A', 'N01B', 'N02A', 'N02B', 'N02C', 'N03A', 'N05A', 'N05B', 'N05C',\n",
    "       'N06A', 'N06B', 'N07B', 'NO6B', 'R01A', 'R03A', 'R03B', 'R05D', 'R06A',\n",
    "       'S01A', 'S01G']]\n",
    "        \n",
    "        return self.merged_df, self.dependent_variable_TNE_BO_1095, self.independent_variable \n",
    "    \n",
    "    # To train and view the reasult of binary and multiclass classifier        \n",
    "    def train_classifier_with_medication_diagnosis(self):\n",
    "        dependent_variables = [self.dependent_variable_TNE_BO_1095]\n",
    "        \n",
    "        # to define the weight of output class, to resolve imbalanced output/dataset\n",
    "        dependent_variable_names = {'self.dependent_variable_TNE_BO_1095': 'TNE_BO_1095'}\n",
    "        class_weights = {'TNE_BO_1095': {0:10, 1:270}}\n",
    "              \n",
    "        #for dependent_variable in dependent_variables:\n",
    "        for variable_name, dependent_variable in zip(dependent_variable_names.values(), dependent_variables):\n",
    "            logistic_prediction_model = LogisticRegression(class_weight=class_weights[variable_name])\n",
    "            X_train, X_test, y_train, y_test = train_test_split(self.independent_variable, dependent_variable, train_size=0.7)\n",
    "            logistic_prediction_model.fit(X_train,y_train)\n",
    "            y_pred = logistic_prediction_model.predict(X_test)\n",
    "            \n",
    "            # Checks if the output category for classification is binary or multiclass\n",
    "            category_count = int(y_train.nunique())\n",
    "            print(f'\\n****** Evaluation result {variable_name} as dependent variable ******')\n",
    "            # For binary class classification \n",
    "            if category_count == 2:\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, average='binary')\n",
    "                recall = recall_score(y_test, y_pred, average='binary')\n",
    "                f1 = f1_score(y_test, y_pred, average='binary')\n",
    "                \n",
    "                print(f\"Accuracy: {accuracy}\")\n",
    "                print(f\"Precision: {precision}\")\n",
    "                print(f\"Recall: {recall}\")\n",
    "                print(f\"F1score: {f1}\")\n",
    "                print(\"Confused matrix:\")\n",
    "                conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                tn, fp, fn, tp = conf_matrix.ravel()\n",
    "                print(conf_matrix)\n",
    "                print(f\"True Negative (TN): {tn}\")\n",
    "                print(f\"False Positive (FP): {fp}\")\n",
    "                print(f\"False Negative (FN): {fn}\")\n",
    "                print(f\"True Positive (TP): {tp}\")\n",
    "                print(classification_report(y_test, y_pred))\n",
    "            \n",
    "            # For binary class classification \n",
    "            else:\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, average='weighted')\n",
    "                recall = recall_score(y_test, y_pred, average='weighted')\n",
    "                f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "                \n",
    "                print(f\"Accuracy: {accuracy}\")\n",
    "                print(f\"Precision: {precision}\")\n",
    "                print(f\"Recall: {recall}\")\n",
    "                print(f\"F1score: {f1}\")\n",
    "                conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                print(\"Confused matrix:\")\n",
    "                print(conf_matrix)\n",
    "                print(classification_report(y_test, y_pred))\n",
    "                \n",
    "    def prediction_with_medication_diagnosis(self):\n",
    "        # Select all corresponding columns with values in TNE_NO_1095\n",
    "        self.merged_df = self.merged_df.dropna(subset=['TNE_NO_1095'])\n",
    "        \n",
    "        # define dependent variables\n",
    "        self.dependent_variable_TNE_NO_1095 = self.merged_df[['TNE_NO_1095']]\n",
    "        # define independent variables \n",
    "        self.independent_variable = self.merged_df[['num_diagnoses', 'num_medications', 'remaining_time_countdown', 'var_no_dates_permonth','Length_of_Episode', 'Count_visit', 'Therapy_ratio','Examination_ratio', 'Advisory_ratio',\n",
    "        'TreatmentPlanning_ratio','Outpatient_ratio','Inpatient_daynight_ratio', 'Care_intensity', 'closingcode_0', 'closingcode_1', 'closingcode_2', 'closingcode_3','closingcode_4', 'closingcode_5', 'closingcode_6', 'closingcode_9',\n",
    "        'aftercode_1', 'aftercode_2', 'aftercode_3', 'aftercode_4','aftercode_5', 'gender_0', 'F', 'M', 'MiddleChildhood', 'Preschooler','Teenager',\n",
    "        '010', '0703', '0704', '079', '0792', '1000', '1008',\n",
    "       '1009', '1011', '1013', '1015', '136', '1499', '1551', '1701', '1702',\n",
    "       '18911', '1911', '19111', '1994', '201', '2022', '20411', '20421',\n",
    "       '2441', '2442', '2444', '2445', '24521', '2501', '25011', '2502',\n",
    "       '2531', '25311', '2532', '2553', '2564', '259', '260', '2602', '2612',\n",
    "       '2614', '262', '2701', '2713', '27614', '2781', '2791', '2801', '28731',\n",
    "       '288', '28811', '2903', '2911', '2914', '2922', '295', '2951', '2952',\n",
    "       '2953', '296', '2961', '29622', '2972', '300', '3001', '3003', '3004',\n",
    "       '3008', '3009', '301', '3011', '3012', '302', '303', '3031', '3033',\n",
    "       '3034', '304', '3052', '306', '3069', '312', '3123', '313', '3131',\n",
    "       '3132', '3133', '315', '3151', '3152', '3153', '316', '317', '323',\n",
    "       '324', '327', '3274', '32741', '3275', '3276', '3311', '339', '340',\n",
    "       '3401', '341', '343', '344', '345', '3451', '34511', '34512', '3453',\n",
    "       '347', '3484', '357', '3591', '3592', '3621', '365', '3671', '3672',\n",
    "       '3678', '3679', '368', '3681', '3684', '3695', '3711', '3781', '3782',\n",
    "       '3811', '389', '3891', '3892', '3894', '3895', '42711', '4332', '4338',\n",
    "       '4589', '472', '4741', '4742', '476', '4801', '495', '496', '499',\n",
    "       '506', '5091', '510', '53011', '53014', '5302', '5305', '535', '5551',\n",
    "       '5552', '55521', '558', '5611', '563', '564', '5641', '565', '57181',\n",
    "       '5772', '591', '5921', '5965', '5994', '6041', '62611', '6264', '637',\n",
    "       '6491', '656', '6562', '6563', '6564', '657', '658', '661', '691',\n",
    "       '6941', '69542', '6964', '7061', '71011', '7142', '7169', '7282',\n",
    "       '7321', '733', '736', '7373', '739', '745', '7471', '74711', '74712',\n",
    "       '74713', '7472', '748', '749', '7491', '7492', '75011', '75013',\n",
    "       '75021', '75112', '7512', '75121', '75211', '7522', '7531', '7551',\n",
    "       '7554', '7556', '75561', '756', '7561', '758', '7581', '759', '760',\n",
    "       '770', '773', '7981', '8003', '802', '8032', '8033', '805', '817',\n",
    "       '818', '819', '830', '835', '871', '907', '915', '930', '939', '946',\n",
    "       '947', '949', '969', '979', '981', 'A02B', 'A03F', 'A06A', 'A06B',\n",
    "       'A07A', 'A10B', 'A11E', 'A12A', 'A12B', 'B03A', 'B03B', 'C02A', 'C07A',\n",
    "       'C09A', 'D01A', 'D06A', 'D06B', 'D07A', 'D07B', 'D07X', 'D09A', 'D10A',\n",
    "       'G03A', 'G03C', 'G03F', 'G03H', 'H01B', 'H02A', 'J01C', 'J01F', 'J05A',\n",
    "       'M01A', 'N01B', 'N02A', 'N02B', 'N02C', 'N03A', 'N05A', 'N05B', 'N05C',\n",
    "       'N06A', 'N06B', 'N07B', 'NO6B', 'R01A', 'R03A', 'R03B', 'R05D', 'R06A',\n",
    "       'S01A', 'S01G']]\n",
    "        \n",
    "        dependent_variables = [self.dependent_variable_TNE_NO_1095]\n",
    "        dependent_variable_names = {'self.dependent_variable_TNE_NO_1095':'TNE_NO_1095'}\n",
    "        #for dependent_variable in dependent_variables:\n",
    "        for variable_name, dependent_variable in zip(dependent_variable_names.values(), dependent_variables):\n",
    "            linear_prediction_model = LinearRegression()\n",
    "            X_train, X_temp, y_train, y_temp = train_test_split(self.independent_variable, dependent_variable, train_size=0.7)\n",
    "            X_test,X_eval,y_test,y_eval = train_test_split(X_temp,y_temp,test_size=0.33)\n",
    "            linear_prediction_model.fit(X_train,y_train)\n",
    "            y_pred = linear_prediction_model.predict(X_test)\n",
    "            print(f'\\n****** Prediction Model Evaluation result  {variable_name} as dependent variable ******')\n",
    "            y_pred = linear_prediction_model.predict(X_test)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            print('R-squared:', r2)\n",
    "            print('Mean squared error:', mse)\n",
    "                \n",
    "\n",
    "SplitMedicationDiagnosisInUniquePieces_Obj = SplitMedicationDiagnosisInUniquePieces(os.getenv(\"FILE_Full_Phecode_ATC_PATH\"))\n",
    "SplitMedicationDiagnosisInUniquePieces_Obj.split_diagnosis_medication_in_unique_pieces()\n",
    "\n",
    "ClassifyReadmissionWithMedicationDiagnosis_Obj = ClassifyReadmissionWithMedicationDiagnosis('Split_Full_Phecode_ATC4.csv')\n",
    "merged_df, dependent_variable_TNE_BO_1095, independent_variable  = ClassifyReadmissionWithMedicationDiagnosis_Obj.load_data()\n",
    "ClassifyReadmissionWithMedicationDiagnosis_Obj.train_classifier_with_medication_diagnosis()\n",
    "ClassifyReadmissionWithMedicationDiagnosis_Obj.prediction_with_medication_diagnosis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-P2]",
   "language": "python",
   "name": "conda-env-.conda-P2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
